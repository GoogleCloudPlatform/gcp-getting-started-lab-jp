#!/usr/bin/env python3
"""
BigQuery ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Google Trends ãƒ‘ãƒ–ãƒªãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ç¢ºèªã¨ãƒ“ãƒ¥ãƒ¼ã®ä½œæˆ
"""

import os
from google.cloud import bigquery
from google.cloud.exceptions import Conflict, NotFound
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)

def setup_bigquery_for_minitap(project_id: str):
    """MiniTAPç”¨ã®BigQueryç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    
    try:
        # BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        client = bigquery.Client(project=project_id)
        logger.info(f"BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†: {project_id}")
        
        # 1. ãƒ‘ãƒ–ãƒªãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
        logger.info("Google Trendsãƒ‘ãƒ–ãƒªãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆä¸­...")
        
        test_query = """
        SELECT 
            COUNT(*) as total_records,
            COUNT(DISTINCT country_code) as countries,
            MIN(week) as earliest_week,
            MAX(week) as latest_week
        FROM `bigquery-public-data.google_trends.international_top_terms`
        WHERE week >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
        """
        
        query_job = client.query(test_query)
        results = list(query_job.result())
        
        if results:
            result = results[0]
            logger.info("âœ… ãƒ‘ãƒ–ãƒªãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹æˆåŠŸ!")
            logger.info(f"   ğŸ“Š ç›´è¿‘7æ—¥é–“ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {result.total_records}")
            logger.info(f"   ğŸŒ å¯¾è±¡å›½æ•°: {result.countries}")
            logger.info(f"   ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“: {result.earliest_week} ï½ {result.latest_week}")
        
        # 2. åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        dataset_id = f"{project_id}.minitap_analytics"
        
        try:
            dataset = bigquery.Dataset(dataset_id)
            dataset.location = "US"
            dataset.description = "MiniTAP Google Trendsåˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"
            
            dataset = client.create_dataset(dataset, exists_ok=True)
            logger.info(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†: {dataset_id}")
            
        except Conflict:
            logger.info(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ—¢å­˜: {dataset_id}")
        
        # 3. ä¾¿åˆ©ãªãƒ“ãƒ¥ãƒ¼ã®ä½œæˆ
        view_id = f"{dataset_id}.recent_global_trends"
        
        view_query = f"""
        CREATE OR REPLACE VIEW `{view_id}` AS
        SELECT
            week,
            country_name,
            country_code,
            term,
            rank,
            refresh_date
        FROM
            `bigquery-public-data.google_trends.international_top_terms`
        WHERE
            week >= DATE_SUB(CURRENT_DATE(), INTERVAL 60 DAY)
        ORDER BY
            week DESC, country_code, rank ASC
        """
        
        query_job = client.query(view_query)
        query_job.result()  # å®Œäº†ã¾ã§å¾…æ©Ÿ
        
        logger.info(f"ğŸ‘ï¸ ãƒ“ãƒ¥ãƒ¼ä½œæˆå®Œäº†: {view_id}")
        
        # 4. ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªã®ãƒ†ã‚¹ãƒˆ
        logger.info("ã‚µãƒ³ãƒ—ãƒ«åˆ†æã‚¯ã‚¨ãƒªã®ãƒ†ã‚¹ãƒˆä¸­...")
        
        sample_query = f"""
        SELECT 
            country_name,
            term,
            AVG(rank) as avg_rank,
            COUNT(*) as appearances
        FROM `{view_id}`
        WHERE week >= DATE_SUB(CURRENT_DATE(), INTERVAL 14 DAY)
        GROUP BY country_name, term
        HAVING appearances >= 2
        ORDER BY country_name, avg_rank
        LIMIT 20
        """
        
        query_job = client.query(sample_query)
        sample_results = list(query_job.result())
        
        logger.info(f"ğŸ§ª ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªæˆåŠŸ: {len(sample_results)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
        
        # 5. è¨­å®šæƒ…å ±ã®å‡ºåŠ›
        config_info = {
            "project_id": project_id,
            "dataset_id": dataset_id,
            "view_id": view_id,
            "public_dataset": "bigquery-public-data.google_trends.international_top_terms",
            "status": "ready"
        }
        
        logger.info("âœ… BigQueryã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†!")
        logger.info("ğŸ“‹ è¨­å®šæƒ…å ±:")
        for key, value in config_info.items():
            logger.info(f"   {key}: {value}")
        
        return config_info
        
    except Exception as e:
        logger.error(f"âŒ BigQueryã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        raise

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    project_id = os.environ.get('GOOGLE_CLOUD_PROJECT', 'nooglerproject123')
    
    logger.info("ğŸš€ MiniTAP BigQueryã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹")
    logger.info(f"ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID: {project_id}")
    
    try:
        config = setup_bigquery_for_minitap(project_id)
        
        # Jupyter Notebookç”¨ã®è¨­å®šã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
        setup_code = f'''
# MiniTAP BigQuery è¨­å®š
GOOGLE_CLOUD_PROJECT = "{config['project_id']}"
DATASET_ID = "{config['dataset_id']}"
VIEW_ID = "{config['view_id']}"
PUBLIC_DATASET = "{config['public_dataset']}"

# BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
from google.cloud import bigquery
client = bigquery.Client(project=GOOGLE_CLOUD_PROJECT)

print("âœ… BigQueryè¨­å®šå®Œäº†")
print(f"ğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {{GOOGLE_CLOUD_PROJECT}}")
print(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {{DATASET_ID}}")
print(f"ğŸ‘ï¸ ãƒ“ãƒ¥ãƒ¼: {{VIEW_ID}}")
'''
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›
        with open("bigquery_config.py", "w", encoding="utf-8") as f:
            f.write(setup_code)
        
        logger.info("ğŸ“ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ: bigquery_config.py")
        logger.info("ğŸ‰ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†! Jupyter Notebookã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
        
    except Exception as e:
        logger.error(f"âŒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å¤±æ•—: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
