{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf0fff45-53b2-4854-81c9-cb3105d0ae42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## パッケージ導入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddadbaec-02d2-4c5a-a683-58d390805f32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade google-genai japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a87d4b-44f2-4260-b129-78bb2bf4da1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "_ = app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4834559b-0b39-43a5-9ac3-db960ce2d666",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 事前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d24641-9f46-4079-9e55-9f93d96286ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "PROJECT_ID = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT_ID[-1]\n",
    "LOCATION = 'us-central1'\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location='us-central1')\n",
    "\n",
    "BUCKET = f'gs://{PROJECT_ID}-handson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce319ef-88ef-471f-9516-93b55a2709bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_s = f'{BUCKET}/mp4/s_Google Cloud Next Tokyo ’24 - Innovators Hive の Day 0 に潜入！ -.mp4'\n",
    "target_n = f'{BUCKET}/mp4/n_Google Cloud Next Tokyo ’24 - Innovators Hive の Day 0 に潜入！ -.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2be287-9dab-48ff-81b4-9ba82f999682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64, copy, json, os, re, time, uuid\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import vertexai\n",
    "from google.cloud import storage\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.genai.types import (\n",
    "    HttpOptions, GenerateContentConfig, GenerateImagesConfig,\n",
    "    Part, UserContent, ModelContent,\n",
    ")\n",
    "\n",
    "import os, json, datetime, pprint\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Image, display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70edf60-0194-42c1-8f61-eadbdd17d8bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_response(system_instruction, contents,\n",
    "                      response_schema, model='gemini-2.0-flash-001'):\n",
    "    client = genai.Client(vertexai=True,\n",
    "                          project=PROJECT_ID, location=LOCATION,\n",
    "                          http_options=HttpOptions(api_version='v1'))\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=GenerateContentConfig(\n",
    "            system_instruction=system_instruction,\n",
    "            temperature=0.1,\n",
    "            response_mime_type='application/json',\n",
    "            response_schema=response_schema,\n",
    "        )\n",
    "    )\n",
    "    return '\\n'.join(\n",
    "        [p.text for p in response.candidates[0].content.parts if p.text]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c4cb9-b829-487e-b94e-c747c0d65faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_json(text):\n",
    "    text = text.replace('```json', '').replace('```', '').replace('\\n', ' ')\n",
    "    return json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5bb58c-6d67-4f37-922e-b5257f50a39a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud storage ls --long {BUCKET}/mp4/s*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dbc16c-6bdf-40fe-9c19-0526d3a421cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = target_s.split('/')[-1]\n",
    "basename = filename.rstrip('.mp4').lstrip('s_')\n",
    "image_dir = f'{BUCKET}/image/{basename}'\n",
    "gsutil_opt = '-o GSUtil:parallel_composite_upload_threshold=150M'\n",
    "local_image_dir = basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aacc43a-c94d-45a9-b748-faece281f6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 静止画像ファイルをローカルにコピー\n",
    "!gcloud storage cp --recursive \"{image_dir}\" ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aca605-5052-4fa5-9a14-f03cd007c516",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## キャラクター抽出 (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46682853-901b-48f6-942d-811039b6231f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_instruction = '''\\\n",
    "You are a video content editor. Work on the following tasks.\n",
    "\n",
    "[task]\n",
    "A. Find characters in the movie and describe the visual appearance of each character as detailed as possible.\n",
    "B. Identify the name of each character you found on task A. If you cannot identify the name, name it \"Unknown\".\n",
    "C. Identify representative scenes for each character where the character visually appears on the screen.\n",
    "\n",
    "[condition]\n",
    "B. The description has more than three sentences.\n",
    "C. The number of scenes for each character is at most three. Each scene is identified with timestamp mm:ss-mm:ss.\n",
    "\n",
    "[format instruction]\n",
    "In Japanese. Output is a JSON list of \"character dict\". \"character dict\" is a JSON dict in the following format:\n",
    "{\n",
    "  \"Character ID\": <Sequential number starting from 1>,\n",
    "  \"Name\": \"<Character name>\",\n",
    "  \"Visual Description\": \"<Visual appearance>\",\n",
    "  \"Scenes\": [ \"<list of timestamp of representative scenes>\" ]\n",
    "}\n",
    "'''\n",
    "\n",
    "response_schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"Character ID\": {\"type\": \"string\",\n",
    "                                 \"description\": \"Sequential number starting from 1\"\n",
    "                },\n",
    "                \"Name\" : {\"type\": \"string\",\n",
    "                          \"description\": \"Character name\"\n",
    "                },\n",
    "                \"Visual Description\": {\"type\": \"string\",\n",
    "                                       \"description\": \"Visual appearance of the character\"\n",
    "                },\n",
    "                \"Scenes\": {\"type\": \"array\",\n",
    "                           \"items\": {\n",
    "                              \"type\": \"string\"\n",
    "                           },\n",
    "                           \"description\": \"list of timestamp of representative scenes\"\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"Character ID\",\n",
    "                \"Name\",\n",
    "                \"Visual Description\",\n",
    "                \"Scenes\"\n",
    "            ],\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70bba56-3426-4156-97aa-d89cafa2d35a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents = UserContent([\n",
    "    Part.from_text(text='[movie]'),\n",
    "    Part.from_uri(file_uri=target_n, mime_type='video/mp4'),\n",
    "])\n",
    "\n",
    "result = generate_response(system_instruction, contents,\n",
    "                           response_schema=response_schema,\n",
    "                           model='gemini-2.0-flash-001')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c9ec7-3307-4853-afe8-302e6486e2e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scenes = load_json(result)\n",
    "jpg_files = !ls \"{local_image_dir}/\"\n",
    "m = 0\n",
    "for c in [s.lstrip('capture').rstrip('.jpg') for s in jpg_files]:\n",
    "    try:\n",
    "        m = max(m, int(c))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for item in scenes:\n",
    "    print('=====')\n",
    "    print(item['Character ID'], item['Name'], item['Visual Description'])\n",
    "    for ts in item['Scenes'][:3]:\n",
    "        ts1, ts2 = ts.split('-')\n",
    "        m1, s1 = ts1.split(':')\n",
    "        ss1 = int(m1) * 60 + int(s1) + 1\n",
    "        m2, s2 = ts2.split(':')\n",
    "        ss2 = int(m2) * 60 + int(s2) + 1\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 5, figsize=(15, 2.5))  # Adjust figsize as needed\n",
    "        axs = axs.ravel()\n",
    "        fig.suptitle(str(item['Character ID']) + ': ' + item['Name'], fontsize=16)\n",
    "        for c, ts in enumerate(np.linspace(max(1, ss1), min(ss2, m), 5)):\n",
    "            ts = int(ts)\n",
    "            mm, ss = divmod(ts - 1, 60)\n",
    "            image_name = f'{local_image_dir}/capture{ts:04d}.jpg'\n",
    "            img = mpimg.imread(image_name)\n",
    "            axs[c].imshow(img)\n",
    "            axs[c].axis('off')\n",
    "            axs[c].set_title(f'{mm:02d}:{ss:02d}')\n",
    "        plt.show()\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bfede0-5500-43a3-a807-b4e8f97f4f3a",
   "metadata": {},
   "source": [
    "キャラクター名はハルシネーションが起きている可能性があるので、外見の記述と参考画像を元にネット検索で正しい名前を検索して、参照用画像ファイルを別途用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc620c6-8633-4162-bea5-15efcd49a2b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chars = !gcloud storage ls \"{image_dir}/characters/*.png\"\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e358afe7-437b-4af5-b207-898eb74a2f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_reference = [\n",
    "    '\\n[Reference information to identify character names]'\n",
    "]\n",
    "image_files = {}\n",
    "for item in chars:\n",
    "    name = item.split('/')[-1].rstrip('.png')\n",
    "    image_files[name] = item\n",
    "    prompt_reference += [\n",
    "        f'The name of following character is \"{name}\"',\n",
    "        Part.from_uri(file_uri=image_files[name], mime_type='image/png')\n",
    "    ]\n",
    "\n",
    "prompt_reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae69e2-512c-4e0b-ab48-045d9c9efcc8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 動画サマリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a7109-281a-4214-ac66-6f2eb8a90f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_instruction = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f27aef-5ce3-4554-aa23-606bd4d2a074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_summary = '''\\\n",
    "You are a video content editor. Work on the following tasks.\n",
    "\n",
    "[task]\n",
    "A. Give an one sentence summary of the movie that can be used as a title of the movie.\n",
    "B. Summarize the content of the movie in five to ten sentences.\n",
    "\n",
    "[condition]\n",
    "A, B. If possible, identify the names of characters. Use the full name on every part of the output.\n",
    "A, B. The output should be based on the objective information in the movie.\n",
    "\n",
    "[format instruction]\n",
    "Answer in Japanese. In the JSON dict with the following format:\n",
    "{\n",
    "  \"Title\": \"<Output of Task A>\",\n",
    "  \"Summary\": \"<Output of Task B>\"\n",
    "}\n",
    "'''\n",
    "\n",
    "# prompt_summary = [prompt_summary] + prompt_reference\n",
    "\n",
    "response_schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"Title\": {\"type\": \"string\",\n",
    "                },\n",
    "                \"Summary\" : {\"type\": \"string\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"Title\",\n",
    "                \"Summary\",\n",
    "            ],\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289008d9-77f4-4339-8f6c-4399d0147840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents = UserContent([\n",
    "    Part.from_text(text=prompt_summary),\n",
    "    Part.from_uri(file_uri=target_n, mime_type='video/mp4'),\n",
    "])\n",
    "\n",
    "result = generate_response(system_instruction, contents,\n",
    "                           response_schema=response_schema,\n",
    "                           model='gemini-2.0-flash-001')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c5dca-9ee5-4242-9e11-7e392b41d763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary = pprint.pformat(load_json(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f361ac9-977c-44d2-9a12-a70ff6001a82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 重要シーン抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec1306-05b7-4123-8372-384fa677ab20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_important_scenes = '''\\\n",
    "You are a video content editor. Work on the following tasks.\n",
    "\n",
    "[task]\n",
    "A. Find around 15 important scenes in the movie with accurate timestamps.\n",
    "B. Give a short summary of each scene and why that scene is important.\n",
    "\n",
    "[condition]\n",
    "A, B. If possible, identify the names of characters. Use the full name on every part of the output.\n",
    "The [summary] section contains the summary of the entire movie.\n",
    "You don't need to use the summary information to find scenes, but the result should be consistent with the summary.\n",
    "\n",
    "[format instruction]\n",
    "In Japanese. Show only the following information.\n",
    "Output in a comma separated list with two columns: <timestamp mm:ss-mm:ss>, <output of task B>\n",
    "Header is: Timestamp, Description\n",
    "\n",
    "[summary]\n",
    "''' + summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85edf8a-6e5e-4cd9-9165-b6d5a718e3bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents = UserContent([\n",
    "    Part.from_text(text=prompt_important_scenes),\n",
    "    Part.from_uri(file_uri=target_n, mime_type='video/mp4'),\n",
    "])\n",
    "\n",
    "important_scenes = generate_response(system_instruction, contents, response_schema=None, model='gemini-2.0-flash-001')\n",
    "print(important_scenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e247b31-75c7-4ee9-a6ae-ddc425eee18c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## シーン情報（ビジュアル情報）取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6595ea61-5675-4b4d-ab86-3982b06b6e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_visuals = '''\\\n",
    "You are a video content editor. Work on the following tasks.\n",
    "\n",
    "[task]\n",
    "A. Split the entire movie into scenes with accurate timestamps from start to the exact end of the movie file.\n",
    "B. Describe what's happening in the scene as detailed as possible.\n",
    "C. Enrich the output of task B by adding visual information of not only characters but also things in the background.\n",
    "\n",
    "[condition]\n",
    "A. The length of each scene is 1 to 15 seconds.\n",
    " - Good example: 00:05-00:08, 00:05-00:18. / Bad example: 00:05-01:14 as the timestamp jumps more than 15 seconds.\n",
    "B, C. Avoid using audio information to describe the scene. Describle only what you see on the screen.\n",
    "B. If possible, identify the names of characters. Use the full name on every part of the output.\n",
    "C. The final description is very detailed, vivid and realistic to covey all the visual information of the scene, using up to three sentences.\n",
    "\n",
    "[format instruction]\n",
    "In Japanese. Show only the following information.\n",
    "Output in a comma separated list with two columns: <timestamp mm:ss-mm:ss>, <output of task C>\n",
    "Header is: Timestamp, Description\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3853bef6-d714-4bf1-8036-04cab3aa96f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents = UserContent([\n",
    "    Part.from_text(text=prompt_visuals),\n",
    "    Part.from_uri(file_uri=target_n, mime_type='video/mp4'),\n",
    "])\n",
    "\n",
    "visual_info = generate_response(system_instruction, contents, response_schema=None, model='gemini-2.0-flash-001')\n",
    "print(visual_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff5ed9c-c145-4e3a-9cd6-fe7ed34cd1de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 音声文字起こし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad2045a-9e5e-4009-9c1b-11a27f8d974e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_transcription = '''\\\n",
    "You are a video content editor. Work on the following tasks.\n",
    "\n",
    "[task]\n",
    "A. Transcript what they are speaking with accurate timestamps.\n",
    "\n",
    "[condition]\n",
    "A. Process the entire movie from start to the exact end of the movie file.\n",
    "A. Identify the name of person who is speaking for each speech. Use the full name on every part of the output. If you cannot identify the name, name it \"Unknown\".\n",
    "\n",
    "[format instruction]\n",
    "In Japanese. Output is a JSON list of \"speech dict\". \"speech dict\" is a JSON dict in the following format:\n",
    "{\n",
    "  \"timestamp\": \"<mm:ss-mm:ss>\",\n",
    "  \"Name\": \"<Name of the speaker>\",\n",
    "  \"Transcription\": \"<Transcription>\"\n",
    "}\n",
    "'''\n",
    "\n",
    "response_schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"timestamp\": {\"type\": \"string\",\n",
    "                                 \"description\": \"<mm:ss-mm:ss>\"\n",
    "                },\n",
    "                \"Name\" : {\"type\": \"string\",\n",
    "                          \"description\": \"Name of the speaker\"\n",
    "                },\n",
    "                \"Transcription\": {\"type\": \"string\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"timestamp\",\n",
    "                \"Name\",\n",
    "                \"Transcription\",\n",
    "            ],\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa04853-0803-4bac-b663-9b68b931e546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents = UserContent([\n",
    "    Part.from_text(text=prompt_transcription),\n",
    "    Part.from_uri(file_uri=target_s, mime_type='video/mp4'),\n",
    "])\n",
    "result = generate_response('Process the entire movie from start to the exact end of the movie file.', contents,\n",
    "                           response_schema=response_schema,\n",
    "                           model='gemini-2.5-pro-preview-05-06')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4c79b-2fe6-4a3a-816b-f1e8a0146edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transcription = pprint.pformat(load_json(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b716f655-14c8-4169-9390-b6403ef01a36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## テキスト情報取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e34bc52-fd46-42dc-9b6e-a81e48dae97b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_texts = '''\\\n",
    "You are a video content editor. Work on the following tasks.\n",
    "\n",
    "[task]\n",
    "A. Extract exact text strings from each scene.\n",
    "\n",
    "[steps]\n",
    "2. Extract text strings from the scene.\n",
    "3. Output the new \"text dict\" that have the \"Text\" element. \"Timestamp\" and \"Layout\" should be the same as the original item.\n",
    "\n",
    "[condition]\n",
    "A. Process the entire movie from start to the exact end of the movie file.A. Output each character literally as on the screen. Don't modify them.\n",
    "A. Use a list to store multiple lines of texts instead of using the return code \\\\n in the extracted text strings.\n",
    "A. Make sure to use double quotes \"\" in the output JSON.\n",
    "\n",
    "[format instruction]\n",
    "Final output is a JSON list of \"text dict\". \"text dict\" is a JSON dict in the following format:\n",
    "{\n",
    "  \"Timestamp\": \"<Timestamp mm:ss-mm:ss>\",\n",
    "  \"Text\": [List of text strings from Task A>],\n",
    "  \"Layout\": \"<layout description>\"\n",
    "}\n",
    "\n",
    "[text layout]\n",
    "'''\n",
    "\n",
    "response_schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"Timestamp\": {\"type\": \"string\",\n",
    "                              \"description\": \"<Timestamp mm:ss-mm:ss>\"\n",
    "                },\n",
    "                \"Text\": {\"type\": \"array\",\n",
    "                           \"items\": {\n",
    "                              \"type\": \"string\"\n",
    "                           },\n",
    "                           \"description\": \"List of text strings from Task A>\"\n",
    "                },\n",
    "                \"Layout\" : {\"type\": \"string\",\n",
    "                            \"description\": \"<layout description>\"\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"Timestamp\",\n",
    "                \"Text\",\n",
    "                \"Layout\",\n",
    "            ],\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "contents = UserContent([\n",
    "    Part.from_text(text=prompt_texts),\n",
    "    Part.from_uri(file_uri=target_n, mime_type='video/mp4'),\n",
    "])\n",
    "\n",
    "result = generate_response('Process the entire movie from start to the exact end of the movie file.', contents,\n",
    "                           response_schema=response_schema,\n",
    "                           model='gemini-2.5-pro-preview-05-06')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5659d04-767b-4f4b-b0c3-97c3b3537e27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = pprint.pformat(load_json(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862db2bc-fa7b-4e76-abf1-007f4a928ed7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## テキストベースの動画内検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c233a-fa66-4b99-b948-c90aa95e30ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_content_search = '''\n",
    "You are a video content editor.\n",
    "\n",
    "Given the following information of a movie:\n",
    "- The [summary] section contains the summary of the movie.\n",
    "- The [important scenes] section contains the important scenes of the movie with timestamps.\n",
    "- The [visual info] section contains the visual information on what's happening in each scene with timestamps.\n",
    "- The [transcription] section contains speech transcription with timestamps.\n",
    "- The [text] section contains text information with timestamps.\n",
    "\n",
    "Find one to three scenes that matches the user query with timestamps.\n",
    "\n",
    "[format instruction]\n",
    "Output in Japanese. Output is a JSON list with \"scene dict\".\n",
    "Each \"scene dict\" is a JSON dict with the following format:\n",
    "{{\n",
    "  \"Timestamp\": \"<timestamp mm:ss-mm:ss>\",\n",
    "  \"Description\": \"<Explain how this scene matches the query.>\",\n",
    "  \"Evidence\": [<List of data snippets that support your result>]\n",
    "}}\n",
    "\n",
    "[user query]\n",
    "{}\n",
    "\n",
    "[summary]\n",
    "{}\n",
    "\n",
    "[important scenes]\n",
    "{}\n",
    "\n",
    "[visual info]\n",
    "{}\n",
    "\n",
    "[transcription]\n",
    "{}\n",
    "\n",
    "[texts]\n",
    "{}\n",
    "'''\n",
    "\n",
    "response_schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"Timestamp\": {\"type\": \"string\",\n",
    "                              \"description\": \"<Timestamp mm:ss-mm:ss>\"\n",
    "                },\n",
    "                \"Description\" : {\"type\": \"string\",\n",
    "                            \"description\": \"Explain how this scene matches the query.\"\n",
    "                },\n",
    "                \"Evidence\": {\"type\": \"array\",\n",
    "                             \"items\": {\n",
    "                                 \"type\": \"string\"\n",
    "                             },\n",
    "                             \"description\": \"List of data snippets that support your result>\"\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"Timestamp\",\n",
    "                \"Description\",\n",
    "                \"Evidence\"\n",
    "            ],\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1020f-cd1e-471f-bb79-51af2a0c695f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_thumbnails(scenes):\n",
    "    jpg_files = !ls \"{local_image_dir}/\"\n",
    "    m = 0\n",
    "    for c in [s.lstrip('capture').rstrip('.jpg') for s in jpg_files]:\n",
    "        try:\n",
    "            m = max(m, int(c))\n",
    "        except:\n",
    "            pass\n",
    "    for item in scenes:\n",
    "        ts = item['Timestamp']\n",
    "        ts1, ts2 = ts.split('-')\n",
    "        m1, s1 = ts1.split(':')\n",
    "        ss1 = int(m1) * 60 + int(s1) + 1\n",
    "        m2, s2 = ts2.split(':')\n",
    "        ss2 = int(m2) * 60 + int(s2) + 1\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 5, figsize=(15, 2))  # Adjust figsize as needed\n",
    "        axs = axs.ravel()\n",
    "        print('=====')\n",
    "        print(str(item['Description']))\n",
    "        # 報告されたタイムスタンプの前後 3 秒を含めて 5 枚の静止画像を表示する\n",
    "        for c, ts in enumerate(np.linspace(max(1, ss1-3), min(ss2+3, m), 5)):\n",
    "            ts = int(ts)\n",
    "            mm, ss = divmod(ts - 1, 60)\n",
    "            image_name = f'{local_image_dir}/capture{ts:04d}.jpg'\n",
    "            img = mpimg.imread(image_name)\n",
    "            axs[c].imshow(img)\n",
    "            axs[c].axis('off')\n",
    "            axs[c].set_title(f'{mm:02d}:{ss:02d}')\n",
    "        plt.show()\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778345d0-ecab-4a65-8a52-d4b8011ddf17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "query = '視聴者の興味を惹く面白そうなシーン'\n",
    "prompt = prompt_content_search.format(\n",
    "    query, summary, important_scenes, visual_info, transcription, texts)\n",
    "# result = generate(prompt, model=model_flash)\n",
    "\n",
    "contents = UserContent([\n",
    "    Part.from_text(text=prompt),\n",
    "])\n",
    "result = generate_response(system_instruction, contents,\n",
    "                           response_schema=response_schema,\n",
    "                           model='gemini-2.0-flash-001')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c322fa-1c88-47ec-a3b6-fd3b76734d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_thumbnails(load_json(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb80ff-1716-402f-92b4-8afc4685d741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "query = '複数の人物が会話しているシーン'\n",
    "prompt = prompt_content_search.format(\n",
    "    query, summary, important_scenes, visual_info, transcription, texts)\n",
    "\n",
    "contents = UserContent([\n",
    "    Part.from_text(text=prompt),\n",
    "])\n",
    "\n",
    "result = generate_response(system_instruction, contents,\n",
    "                           response_schema=response_schema,\n",
    "                           model='gemini-2.0-flash-001')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b0e9a-57d5-4055-b9ed-4e4d8c2f42e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_thumbnails(load_json(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87ac55-b660-4a82-b513-8050e1c4065d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "query = '会場を歩いているシーン'\n",
    "prompt = prompt_content_search.format(\n",
    "    query, summary, important_scenes, visual_info, transcription, texts)\n",
    "\n",
    "contents = UserContent([\n",
    "    Part.from_text(text=prompt),\n",
    "])\n",
    "\n",
    "result = generate_response(system_instruction, contents,\n",
    "                           response_schema=response_schema,\n",
    "                           model='gemini-2.0-flash-001')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe916ac2-b9e1-4a0c-be7d-de21fa920d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_thumbnails(load_json(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2163d3a1-b16b-4f5b-a810-630617da2b20",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 動画ベースの動画内検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03018a-9f9a-4ad8-bd56-652a22e88045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_movie_content_search = '''\\\n",
    "You are a video content editor.\n",
    "Find one to three scenes that matches the user query with timestamps.\n",
    "\n",
    "[condition]\n",
    "Try to identify names of characters.\n",
    "The result should be based on the objective information in the movie itself.\n",
    "\n",
    "[user query]\n",
    "{}\n",
    "\n",
    "[format instruction]\n",
    "Output in Japanese. Output is a JSON list with \"scene dict\".\n",
    "Each \"scene dict\" is a JSON dict with the following format:\n",
    "{{\n",
    "  \"Timestamp\": \"<timestamp mm:ss-mm:ss>\",\n",
    "  \"Description\": \"<Explain how this scene matches the query.>\"\n",
    "}}\n",
    "'''\n",
    "\n",
    "response_schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"Timestamp\": {\"type\": \"string\",\n",
    "                              \"description\": \"<Timestamp mm:ss-mm:ss>\"\n",
    "                },\n",
    "                \"Description\" : {\"type\": \"string\",\n",
    "                            \"description\": \"Explain how this scene matches the query.\"\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"Timestamp\",\n",
    "                \"Description\"\n",
    "            ],\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c434d74-32c8-4ca4-8c3f-69bf16302455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "query = '視聴者の興味を惹く面白そうなシーン'\n",
    "prompt = prompt_movie_content_search.format(query)\n",
    "\n",
    "contents = UserContent([\n",
    "    Part.from_text(text=prompt),\n",
    "    Part.from_uri(file_uri=target_n, mime_type='video/mp4'),\n",
    "])\n",
    "\n",
    "result = generate_response(system_instruction, contents,\n",
    "                           response_schema=response_schema,\n",
    "                           model='gemini-2.0-flash-001')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fad0ae-32a4-4faa-b918-f41a508d17b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_thumbnails(load_json(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5074be-5318-49b8-992d-98d09afc7b9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "query = '複数の人物が会話しているシーン'\n",
    "prompt = prompt_movie_content_search.format(query)\n",
    "contents = UserContent([\n",
    "    Part.from_text(text=prompt),\n",
    "    Part.from_uri(file_uri=target_n, mime_type='video/mp4'),\n",
    "])\n",
    "\n",
    "result = generate_response(system_instruction, contents,\n",
    "                           response_schema=response_schema,\n",
    "                           model='gemini-2.0-flash-001')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa83ed1-0a64-4623-a310-e25db4f73514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_thumbnails(load_json(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22946f-ec8c-44bb-baee-ebd4fef9ea4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "query = '会場を歩いているシーン'\n",
    "prompt = prompt_movie_content_search.format(query)\n",
    "contents = UserContent([\n",
    "    Part.from_text(text=prompt),\n",
    "    Part.from_uri(file_uri=target_n, mime_type='video/mp4'),\n",
    "])\n",
    "\n",
    "result = generate_response(system_instruction, contents,\n",
    "                           response_schema=response_schema,\n",
    "                           model='gemini-2.0-flash-001')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0233b4a3-d67c-4f54-b219-54c70e18521a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_thumbnails(load_json(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af79c0ac-2fde-402c-b99d-147f2bc63c6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 検索用メタテキストを保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa010db3-2f7d-41ee-b662-3fcd3d25e70c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_text = '''\\\n",
    "[summary]\n",
    "{}\n",
    "\n",
    "[important scenes]\n",
    "{}\n",
    "\n",
    "[visual info]\n",
    "{}\n",
    "\n",
    "[transcription]\n",
    "{}\n",
    "\n",
    "[texts]\n",
    "{}'''.format(summary, important_scenes, visual_info, transcription, texts)\n",
    "\n",
    "metafile = f'{basename}.txt'\n",
    "with open(metafile, 'w') as f:\n",
    "    f.write(meta_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f7ce8-09a9-45a8-8e80-4fe7ca72ba47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud storage cp \"{metafile}\" {BUCKET}/metadata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db8f00-4478-43e1-aca1-658574f4d677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(meta_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d431e-c13d-49d3-81c1-ea845026595d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
