{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy TRTIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trtis_service.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile trtis_service.yaml\n",
    "\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  labels:\n",
    "    name: inference-server\n",
    "  name: inference-server\n",
    "  namespace: default\n",
    "spec:\n",
    "  #externalTrafficPolicy: Cluster\n",
    "  ports:\n",
    "  - name: http-inference-server\n",
    "    port: 8000\n",
    "    protocol: TCP\n",
    "    targetPort: 8000\n",
    "  - name: grpc-inference-server\n",
    "    port: 8001\n",
    "    protocol: TCP\n",
    "    targetPort: 8001\n",
    "  - name: metrics-inference-server\n",
    "    port: 8002\n",
    "    protocol: TCP\n",
    "    targetPort: 8002\n",
    "  selector:\n",
    "    app: inference-server\n",
    "  sessionAffinity: None\n",
    "  type: ClusterIP\n",
    "  #type: LoadBalancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trtis_deploy.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile trtis_deploy.yaml\n",
    "\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: inference-server\n",
    "  labels:\n",
    "    name: inference-server\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: inference-server\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: inference-server\n",
    "    spec:\n",
    "      dnsPolicy: ClusterFirst\n",
    "      imagePullSecrets:\n",
    "      - name: ngc\n",
    "      priority: 0\n",
    "      restartPolicy: Always\n",
    "      schedulerName: default-scheduler\n",
    "      securityContext: {}\n",
    "      serviceAccount: default\n",
    "      serviceAccountName: default\n",
    "      terminationGracePeriodSeconds: 30\n",
    "      containers:\n",
    "      - args:\n",
    "        - trtserver\n",
    "        - --model-store=gs://sandbox-kathryn-models/resnet/\n",
    "        image: nvcr.io/nvidia/tensorrtserver:19.05-py3\n",
    "        imagePullPolicy: IfNotPresent\n",
    "        livenessProbe:\n",
    "          failureThreshold: 3\n",
    "          httpGet:\n",
    "            path: /api/health/live\n",
    "            port: 8000\n",
    "            scheme: HTTP\n",
    "          initialDelaySeconds: 5\n",
    "          periodSeconds: 5\n",
    "          successThreshold: 1\n",
    "          timeoutSeconds: 1\n",
    "        name: inference-server\n",
    "        ports:\n",
    "        - containerPort: 8000\n",
    "          protocol: TCP\n",
    "        - containerPort: 8001\n",
    "          protocol: TCP\n",
    "        - containerPort: 8002\n",
    "          protocol: TCP\n",
    "        readinessProbe:\n",
    "          failureThreshold: 3\n",
    "          httpGet:\n",
    "            path: /api/health/ready\n",
    "            port: 8000\n",
    "            scheme: HTTP\n",
    "          initialDelaySeconds: 5\n",
    "          periodSeconds: 5\n",
    "          successThreshold: 1\n",
    "          timeoutSeconds: 1\n",
    "        resources:\n",
    "          limits:\n",
    "            nvidia.com/gpu: \"1\"\n",
    "          requests:\n",
    "            cpu: 1000m\n",
    "            nvidia.com/gpu: \"1\"\n",
    "        securityContext:\n",
    "          procMount: Default\n",
    "          runAsUser: 1000\n",
    "        terminationMessagePath: /dev/termination-log\n",
    "        terminationMessagePolicy: File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service \"inference-server\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f trtis_service.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/inference-server created\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f trtis_service.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)                                        AGE\n",
      "inference-server   ClusterIP      10.59.254.225   <none>          8000/TCP,8001/TCP,8002/TCP                     6m22s\n",
      "kubernetes         ClusterIP      10.59.240.1     <none>          443/TCP                                        104m\n",
      "locust-master      LoadBalancer   10.59.242.220   35.200.99.104   8089:32253/TCP,5557:30210/TCP,5558:30840/TCP   62m\n"
     ]
    }
   ],
   "source": [
    "!kubectl get svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                READY   STATUS    RESTARTS   AGE\n",
      "inference-server-56588945c6-27l95   1/1     Running   0          36m\n",
      "locust-master-795dc864b4-2qllm      1/1     Running   0          4m25s\n",
      "locust-slave-744f96d97c-7cjcp       1/1     Running   0          4m24s\n",
      "locust-slave-744f96d97c-q8zxr       1/1     Running   0          4m24s\n",
      "locust-slave-744f96d97c-qfvvd       1/1     Running   0          4m24s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)                                        AGE\n",
      "inference-server   ClusterIP      10.59.246.232   <none>          8000/TCP,8001/TCP,8002/TCP                     21m\n",
      "kubernetes         ClusterIP      10.59.240.1     <none>          443/TCP                                        54m\n",
      "locust-master      LoadBalancer   10.59.242.220   35.200.99.104   8089:32253/TCP,5557:30210/TCP,5558:30840/TCP   12m\n"
     ]
    }
   ],
   "source": [
    "!kubectl get svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/inference-server created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f trtis_deploy.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                READY   STATUS    RESTARTS   AGE\n",
      "inference-server-56588945c6-27l95   1/1     Running   0          3m55s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Prometheus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting clusterRole.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile clusterRole.yml\n",
    "\n",
    "apiVersion: rbac.authorization.k8s.io/v1beta1\n",
    "kind: ClusterRole\n",
    "metadata:\n",
    "  name: prometheus\n",
    "rules:\n",
    "- apiGroups: [\"\"]\n",
    "  resources:\n",
    "  - nodes\n",
    "  - nodes/proxy\n",
    "  - services\n",
    "  - endpoints\n",
    "  - pods\n",
    "  verbs: [\"get\", \"list\", \"watch\"]\n",
    "- apiGroups:\n",
    "  - extensions\n",
    "  resources:\n",
    "  - ingresses\n",
    "  verbs: [\"get\", \"list\", \"watch\"]\n",
    "- nonResourceURLs: [\"/metrics\"]\n",
    "  verbs: [\"get\"]\n",
    "---\n",
    "apiVersion: rbac.authorization.k8s.io/v1beta1\n",
    "kind: ClusterRoleBinding\n",
    "metadata:\n",
    "  name: prometheus\n",
    "roleRef:\n",
    "  apiGroup: rbac.authorization.k8s.io\n",
    "  kind: ClusterRole\n",
    "  name: prometheus\n",
    "subjects:\n",
    "- kind: ServiceAccount\n",
    "  name: default\n",
    "  namespace: monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\n",
      "inference-server   ClusterIP   10.59.246.232   <none>        8000/TCP,8001/TCP,8002/TCP   41s\n",
      "kubernetes         ClusterIP   10.59.240.1     <none>        443/TCP                      33m\n"
     ]
    }
   ],
   "source": [
    "!kubectl get svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.59.246.232"
     ]
    }
   ],
   "source": [
    "!kubectl get svc inference-server -o \"jsonpath={.spec['clusterIP']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting prometheus-configmap.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile prometheus-configmap.yml\n",
    "\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: prometheus-server-conf\n",
    "  labels:\n",
    "    name: prometheus-server-conf\n",
    "  namespace: monitoring\n",
    "data:\n",
    "  prometheus.yml: |-\n",
    "    # my global config\n",
    "    global:\n",
    "      scrape_interval:     10s\n",
    "      evaluation_interval: 10s\n",
    "      # scrape_timeout is set to the global default (10s).\n",
    "\n",
    "    # Alertmanager configuration\n",
    "    alerting:\n",
    "      alertmanagers:\n",
    "      - static_configs:\n",
    "        - targets:\n",
    "          # - alertmanager:9093\n",
    "\n",
    "    # Load rules once and periodically evaluate them according to the global 'evaluation_interval'.\n",
    "    rule_files:\n",
    "      # - \"first_rules.yml\"\n",
    "      # - \"second_rules.yml\"\n",
    "\n",
    "    # A scrape configuration containing exactly one endpoint to scrape:\n",
    "    # Here it's Prometheus itself.\n",
    "    scrape_configs:\n",
    "      # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\n",
    "      - job_name: 'prometheus'\n",
    "\n",
    "        # metrics_path defaults to '/metrics'\n",
    "        # scheme defaults to 'http'.\n",
    "\n",
    "        static_configs:\n",
    "        - targets: ['10.59.254.225:8002']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting prometheus-deployment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile prometheus-deployment.yml\n",
    "\n",
    "apiVersion: extensions/v1beta1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: prometheus-deployment\n",
    "  namespace: monitoring\n",
    "spec:\n",
    "  replicas: 1\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: prometheus-server\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: prometheus\n",
    "          image: prom/prometheus:latest\n",
    "          args:\n",
    "            - \"--config.file=/etc/prometheus/prometheus.yml\"\n",
    "            - \"--storage.tsdb.path=/prometheus/\"\n",
    "          ports:\n",
    "            - containerPort: 9090\n",
    "          volumeMounts:\n",
    "            - name: prometheus-config-volume\n",
    "              mountPath: /etc/prometheus\n",
    "            - name: prometheus-storage-volume\n",
    "              mountPath: /prometheus\n",
    "      volumes:\n",
    "        - name: prometheus-config-volume\n",
    "          configMap:\n",
    "            defaultMode: 420\n",
    "            name: prometheus-server-conf\n",
    "        - name: prometheus-storage-volume\n",
    "          emptyDir: {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting prometheus-service.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile prometheus-service.yml\n",
    "\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: prometheus-service\n",
    "spec:\n",
    "  selector: \n",
    "    app: prometheus-server\n",
    "  type: ClusterIP\n",
    "  ports:\n",
    "    - port: 8080\n",
    "      targetPort: 9090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): namespaces \"monitoring\" already exists\n"
     ]
    }
   ],
   "source": [
    "!kubectl create namespace monitoring\n",
    "!kubectl create -f clusterRole.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap \"prometheus-server-conf\" deleted\n",
      "deployment.extensions \"prometheus-deployment\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f prometheus-configmap.yml -n monitoring\n",
    "!kubectl delete -f prometheus-deployment.yml -n monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap/prometheus-server-conf created\n",
      "deployment.extensions/prometheus-deployment created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f prometheus-configmap.yml -n monitoring\n",
    "!kubectl apply -f prometheus-deployment.yml -n monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f prometheus-service.yml -n monitoring\n",
    "!kubectl apply -f prometheus-service.yml -n monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)          AGE\n",
      "grafana-service      LoadBalancer   10.59.242.109   35.243.122.150   8100:30019/TCP   88m\n",
      "prometheus-service   ClusterIP      10.59.249.144   <none>           8080/TCP         6s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get svc -n monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Grafana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting grafana-deployment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile grafana-deployment.yml\n",
    "\n",
    "apiVersion: extensions/v1beta1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: grafana-deployment\n",
    "  namespace: monitoring\n",
    "spec:\n",
    "  replicas: 1\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: grafana-server\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: grafana\n",
    "          image: grafana/grafana:latest\n",
    "          #args:\n",
    "          #  - \"--config.file=/root/prometheus.yml\"\n",
    "          #  - \"--storage.tsdb.path=/prometheus/\"\n",
    "          ports:\n",
    "            - containerPort: 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting grafana-service.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile grafana-service.yml\n",
    "\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: grafana-service\n",
    "spec:\n",
    "  selector: \n",
    "    app: grafana-server\n",
    "  type: LoadBalancer\n",
    "  ports:\n",
    "    - port: 8100\n",
    "      targetPort: 3000\n",
    "      #nodePort: 30020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.extensions/grafana-deployment created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f grafana-deployment.yml -n monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                     READY   STATUS              RESTARTS   AGE\n",
      "grafana-deployment-644bbcb84-qlb2t       0/1     ContainerCreating   0          0s\n",
      "prometheus-deployment-544b9b9f98-ml2vs   1/1     Running             0          2m3s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods -n monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/grafana-service created\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f grafana-service.yml -n monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)          AGE\n",
      "grafana-service      LoadBalancer   10.59.242.109   35.243.122.150   8100:30019/TCP   31h\n",
      "prometheus-service   ClusterIP      10.59.249.144   <none>           8080/TCP         30h\n"
     ]
    }
   ],
   "source": [
    "!kubectl get svc -n monitoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
