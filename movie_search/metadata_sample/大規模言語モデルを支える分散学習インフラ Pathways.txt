[summary]
{'Summary': 'Google Cloud のソリューションズアーキテクトである中井 '
            '悦司氏は、大規模言語モデルを支える分散学習インフラPathwaysについて解説しました。中井 '
            '悦司氏は、従来の機械学習モデルはシングルモーダル、シングルタスクであったのに対し、Pathwaysはマルチモーダル、マルチタスクであると説明しました。中井 '
            '悦司氏は、Pathwaysのアイデアが生まれた背景として、2012年にGoogleのJeff '
            'Dean氏が発表したディープラーニングに関する研究成果を紹介しました。この研究成果により、ニューラルネットワークのサイズを大きくすればするほど性能が向上することが示されました。中井 '
            '悦司氏は、マルチモーダルなモデルの例として、自然言語で文章を入力すると、その文章にマッチした画像を生成する画像生成モデルを紹介しました。中井 '
            '悦司氏は、マルチモーダルに対応したモデルの仕組みとして、入力データの形式に合わせて個別に前処理を行い、意味を表す抽象的な潜在空間のベクトルに変換することを説明しました。中井 '
            '悦司氏は、Pathwaysの実現に向けた技術開発として、Googleが開発したTPUを用いた分散学習システムを紹介しました。中井 '
            '悦司氏は、Pathwaysが今後、生成系AIやマルチモーダル、マルチタスクなモデルの学習に利用できるようになると期待されると述べました。最後に、Google '
            'Cloud マーケティングの北瀬 公彦氏が登壇し、質疑応答が行われました。北瀬 公彦氏は、GKEでTPU '
            'Podを利用できるかどうか、現在注目しているAI技術は何か、プロンプトチューニングはモデルそのものをチューニングしているわけではないか、今後モデルのサイズを圧縮する技術が発展しても、やはり大規模なモデルは必要なのか、といった質問に対して、中井 '
            '悦司氏が回答しました。',
 'Title': '大規模言語モデルを支える分散学習インフラPathways'}

[important scenes]
Timestamp, Description
00:16-00:18, Google Cloud のソリューションズアーキテクトである中井 悦司氏が自己紹介をしています。
00:21-00:26, 中井 悦司氏が、大規模言語モデルを支える分散学習インフラPathwaysについて約30分間お話をすることを伝えています。
00:37-01:02, 中井 悦司氏が、Pathwaysというキーワードが初めて登場したのは、2021年にGoogleの機械学習ML研究チームのトップであるJeff Dean氏が発表したブログ記事であることを説明しています。
01:03-01:10, 中井 悦司氏が、Jeff Dean氏のブログ記事では、将来の機械学習モデルのアーキテクチャについて語られており、従来の機械学習モデルはシングルモーダル、シングルタスクであったのに対し、Pathwaysはマルチモーダル、マルチタスクであると説明しています。
01:29-01:52, 中井 悦司氏が、2022年にGoogleがPathways Language Model（PaLM）という大規模自然言語モデルの開発に成功したという発表があったことを説明しています。
01:52-02:25, 中井 悦司氏が、PaLMは自然言語モデルであり、自然言語という特定の形式のデータだけを取り扱っていること、テキスト文の前半から後半を予測するという特定のタスクしかやっていないことを説明しています。
02:25-03:16, 中井 悦司氏が、PaLMはシングルモーダル、シングルタスクの機械学習モデルであり、Jeff Dean氏のブログ記事にあったマルチモーダル、マルチタスクのPathwaysとは少し違うことを説明し、なぜ自然言語モデルにPathwaysというキーワードが入っているのか、その謎を解き明かしたいと述べています。
03:22-04:16, 中井 悦司氏が、2012年にGoogle社内でディープラーニングが広く使われるようになったきっかけとなった研究成果を紹介しています。YouTubeの動画データに非常に階層の深いニューラルネットワークを適用したところ、様々な物体を認識することに成功したという研究成果です。
04:16-04:57, 中井 悦司氏が、Google社内でディープラーニングの技術があらゆるプロダクトに利用されるようになったこと、機械学習モデル、ディープラーニングモデルのサイズがどんどん大きくなっていくという流れがあることを説明しています。
04:57-05:58, 中井 悦司氏が、モデルのサイズが大きいほど性能が向上するニューラルスケーリングローという名前があること、それを実証する事例として、2020年に発表されたGPT-3という自然言語モデルと、2021年にGoogleが発表したGLaMモデルを紹介しています。
06:14-07:22, 中井 悦司氏が、モデルのサイズが大きくなると、単純に性能が向上するだけでなく、マルチモーダルにも対応できるようになることを説明し、自然言語で文章を入力すると、その文章にマッチした画像を生成する画像生成モデルの例を紹介しています。
07:24-08:13, 中井 悦司氏が、マルチモーダルに対応したもう1つの例として、ロボットアームを操作するモデルを紹介しています。テキスト文や動画で命令を入力すると、ロボットアームがその通りに動いてくれるというモデルです。
08:13-09:34, 中井 悦司氏が、マルチモーダルに対応したモデルの仕組みとして、入力データの形式に合わせて個別に前処理を行い、意味を表す抽象的な潜在空間のベクトルに変換することを説明しています。
09:34-10:00, 中井 悦司氏が、マルチモーダル、マルチタスクのPathwaysのモデル構造について説明しています。
10:41-11:11, 中井 悦司氏が、Pathwaysの実現に向けた技術開発として、Googleが開発したTPUを用いた分散学習システムを紹介しています。
11:11-12:44, 中井 悦司氏が、Google社内では、Googleが開発したTPUというプロセッサでモデルの学習処理を行っていること、TPUコアをインターコネクトという専用線でメッシュ状に結合したクラスタを使って分散学習処理を行っていることを説明しています。
12:44-14:27, 中井 悦司氏が、Pathwaysに対応した大規模モデルの開発として、Googleの研究者がPathways的なモデルに対応した新しい分散学習の仕組みを考え出し、論文発表していること、Google社内でそのインフラも実験的に作られて動いていることを説明しています。
14:27-15:56, 中井 悦司氏が、Pathwaysのインフラを用いた機械学習の実施例として、2022年にGoogleの研究者が発表したPaLMという自然言語モデルを紹介しています。
17:43-18:21, 中井 悦司氏が、Pathwaysはマルチモーダル、マルチタスクに対応した新しい機械学習モデルの考え方であり、それを実現するインフラはできているが、実際にそのインフラで学習されたのはPaLMと呼ばれる自然言語モデルであることを説明しています。
18:24-18:51, 北瀬 公彦氏が、中井 悦司氏の勉強方法について質問しています。
18:51-19:13, 中井 悦司氏が、GKEでTPU Podを利用できるかどうかという質問に対して、現状ではTPU PodをダイレクトにGKEにアサインすることはできないと回答しています。
19:13-20:20, 中井 悦司氏が、現在注目しているAI技術は何かという質問に対して、生成系AIとそのアーキテクチャに興味があると回答しています。
20:22-21:54, 北瀬 公彦氏が、プロンプトチューニングはモデルそのものをチューニングしているわけではないか、今後モデルのサイズを圧縮する技術が発展しても、やはり大規模なモデルは必要なのか、といった質問に対して、中井 悦司氏が回答しています。
21:56-23:05, 北瀬 公彦氏がセッションの終了を告げ、中井 悦司氏に感謝の言葉を述べています。

[visual info]
Timestamp, Description
00:00-00:05, 白い背景に、赤、青、黄、緑の幾何学模様で構成された「DAY」の文字が表示されます。文字の下には「Breakout」と表示され、その後「Breakout Session」と表示されます。
00:05-00:11, 白い背景に、赤、青、黄、緑の幾何学模様で構成された「DAY」の文字が表示されます。文字の右上には、同じ幾何学模様で構成された「Tour」の文字が表示されます。
00:11-00:18, 白い背景に、プレゼンテーションのタイトル「大規模言語モデルを支える分散学習インフラ Pathways」と、発表者名「中井 悦司 / Etsuji Nakai」、所属「Google Cloud / ソリューションズ アーキテクト」が表示されます。右上には、赤、青、黄、緑の幾何学模様で構成された「DAY Tour」の文字と赤い星が表示されます。
00:18-00:29, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
00:29-00:34, 画面左側に中井 悦司の写真と、彼が執筆したと思われる書籍の表紙が4冊表示されています。右上には「自己紹介」という見出しと、中井 悦司の名前（日本語と英語表記）、所属「Google Cloud / ソリューションズ アーキテクト」が表示されています。
00:34-01:02, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
01:02-01:52, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
01:52-02:14, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
02:14-02:29, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
02:29-03:14, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
03:14-03:21, 白い背景に、プレゼンテーションのタイトル「Pathwaysのアイデアが生まれた背景」が表示されます。タイトルの左上には、赤、青、黄、緑の幾何学模様で構成された「DAY Tour」の文字が表示されます。
03:21-03:46, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
03:46-04:16, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
04:16-04:28, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
04:28-05:08, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
05:08-05:29, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
05:29-06:14, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
06:14-07:06, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
07:06-07:23, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
07:23-08:13, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
08:13-09:34, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
09:34-10:41, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
10:41-11:12, 白い背景に、プレゼンテーションのタイトル「Pathwaysの実現に向けた技術開発」が表示されます。タイトルの左上には、赤、青、黄、緑の幾何学模様で構成された「DAY Tour」の文字が表示されます。
11:12-12:12, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
12:12-12:44, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
12:44-14:27, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
14:27-15:56, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
15:56-17:26, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
17:26-18:18, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
18:18-18:24, 白い背景に、赤、青、黄、緑の幾何学模様で構成された「DAY」の文字が表示されます。文字の右上には、同じ幾何学模様で構成された「Tour」の文字が表示され、その下に「Thank you.」と表示されます。
18:24-18:37, 黒いジャケットに白いTシャツを着た北瀬 公彦が、カラフルな幾何学模様の背景の前に立って話しています。北瀬 公彦の右には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
18:37-19:12, 黒いジャケットに白いTシャツを着た北瀬 公彦が、カラフルな幾何学模様の背景の前に立って話しています。北瀬 公彦の右には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
19:12-19:46, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
19:46-20:21, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
20:21-21:55, 黒いシャツを着た中井 悦司が、カラフルな幾何学模様の背景の前に立って話しています。中井 悦司の左には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
21:55-23:06, 黒いジャケットに白いTシャツを着た北瀬 公彦が、カラフルな幾何学模様の背景の前に立って話しています。北瀬 公彦の右には、白い演台があり、その側面には「DAY Tour」の文字が縦書きで書かれています。
23:06-23:15, 白い背景に「Google Cloud」のロゴが表示されます。

[transcription]
[{'Name': '中井 悦司',
  'Transcription': 'はい 皆さん こんにちは Google Cloud ソリューションズ アーキテクト の 中井 です え 今日 私 の '
                   '方 から は こちら の タイトル で ま 約 30 分間 お 話 を さ せ て いただき ます よろしく お '
                   '願い いたし ます',
  'timestamp': '00:14-00:26'},
 {'Name': '中井 悦司',
  'Transcription': 'はい で こちら いつも の 自己 紹介 スライド です ね よろしく お 願い いたし ます',
  'timestamp': '00:28-00:33'},
 {'Name': '中井 悦司',
  'Transcription': 'で 早速 中身 の 方 入っ て いき たい と 思い ます が 今日 私 の セッション の タイトル の 中 に '
                   'パスウェイズ と いう キーワード が あり まし た この キーワード 皆さん 聞い た こと あり ます '
                   'でしょう か え 実 は パスウェイズ と いう 言葉 が 初めて 登場 し た の が こちら の ブログ 記事 '
                   'な ん です ね 2021 年 2 年 前 に え Google の え 機械 学習 ML 研究 チーム の トップ '
                   'です ね ジェフ ディーン が 発表 し た ブログ 記事 に なり ます で この ブログ の 中 で ジェフ '
                   'ディーン は ま 今後 の 将来 の 機械 学習 モデル の アーキテクチャ を 語っ て いる ん です ね 従来 '
                   'の 機械 学習 モデル と いう の は 基本 的 に は え シングル モデル シングル タスク 何 か 特定 の '
                   '形式 の データ だけ を 扱っ て 何 か 特定 の タスク 特定 の 仕事 を する ため に ま 専用 に '
                   'えっと チューニング さ れ た 開発 さ れ た モデル と いう の が 基本 でし た',
  'timestamp': '00:34-01:02'},
 {'Name': '中井 悦司',
  'Transcription': 'で それ に 対し て 今後 は マルチモーダル マルチタスク いろんな 形式 の データ を 同時 に 取り扱っ '
                   'て かつ え いろんな タスク を 並列 に こなし て いく そんな 機械 学習 モデル が 主流 に なっ て '
                   'いく ま 少なく とも Google の 研究 チーム は そう いっ た モデル の 開発 を これ から 目指し '
                   'て いく と いう こと を 語っ て いる ん です ね で その 後 翌年 な ん です けど も また この '
                   'パスウェイズ と いう キーワード が 登場 し まし た',
  'timestamp': '01:30-01:52'},
 {'Name': '中井 悦司',
  'Transcription': 'これ 昨年 の Google IO で も 語ら れ て い た の で 覚え てる 方 いらっしゃる か も しれ '
                   'ませ ん が パスウェイズ ランゲージ モデル ま 略 し て パーム と 呼ば れる え 大 規模 自然 言語 '
                   'モデル の 開発 に 成功 し た と いう 発表 に なり ます で この パーム と いう の が 非常 に '
                   '性能 が 高く て 例えば こう 算数 の 問題 を 解い て み たり え プログラム 言語 を 出力 し たり '
                   'そんな こと が できる と いう の で 話題 に なり まし た ただ 実 は これ 冷静 に 考える と '
                   'ちょっと 話 が ずれ て いる ん です ね この パーム と いう の は 自然 言語 モデル 自然 言語 と '
                   'いう 特定 の 形式 の データ だけ を 取り扱っ て かつ やっ てる こと は え 何 か ある テキスト 文 '
                   'を 入力 する と それ に 続く 後半 の 文章 を こう 予想 し て ジェネレート する ま テキスト 文 の '
                   '前半 から 後半 を 予想 する と いう ある 特定 の タスク しか 実 は やっ て ない ん です ね え '
                   'シングル モデル シングル タスク の 機械 学習 モデル と いう こと で',
  'timestamp': '01:59-02:29'},
 {'Name': '中井 悦司',
  'Transcription': '先ほど の あの ジェフ ディーン の ブログ に あっ た マルチモーダル マルチタスク の パスウェイズ と は '
                   'ちょっと 違う ん です ね ま なぜ じゃあ この 自然 言語 モデル に パスウェイズ と いう キーワード が '
                   '入っ てる の か え 実 は この セッション で は その 謎 を ちょっと え 解き明かし たい と 思っ て '
                   'い ます じゃ ちょっと これ 順番 に 解説 し て いき たい と 思い ます',
  'timestamp': '03:00-03:16'},
 {'Name': '中井 悦司',
  'Transcription': 'まず こちら 復習 に なり ます が Google 社内 で ま いわゆる ディープ ラーニング 非常 に 階層 '
                   'の 深い ニューラル ネットワーク が 広く 使わ れる よう に なっ た きっかけ が こちら の え 2012 '
                   '年 の 研究 成果 です ね え YouTube の 動画 の データ に 非常 に 階層 の 深い ニューラル '
                   'ネットワーク を 適用 し た ところ ま いろんな 物体 を 認識 する こと に 成功 し た ま そんな 研究 '
                   '成果 に なり ます ニューラル ネットワーク の 考え 方 自体 は 非常 に 古く から 知ら れ て い て '
                   '研究 さ れ て い た ん です けど も 実 は なかなか その 実用 的 な 精度 が 出 なかっ た ん '
                   'です ね ま 多く の 研究 者 が ニューラル ネットワーク で 実用 化 無理 じゃ ない か と 思っ て い '
                   'た ん です けど も ま Google の 研究 者 は そう で は あり ませ ん と 大量 の データ を '
                   '使っ て 非常 に 階層 の 深い ニューラル ネットワーク を 使え ば 十分 実用 な こと が 実用 的 な '
                   'こと が できる と いう の が 実証 さ れ た え そんな 研究 成果 に なり ます',
  'timestamp': '03:21-04:16'},
 {'Name': '中井 悦司',
  'Transcription': 'で これ 以降 ま Google 社内 で は この ディープ ラーニング の 技術 が あり と あらゆる '
                   'プロダクト に こう 利用 さ れる よう に なっ て いく ん です けど も ま そん 中 で 1 つ 面白い '
                   'え 傾向 が あり まし て こちら です ね え 機械 学習 モデル ディープ ラーニング モデル の サイズ が '
                   'どんどん どんどん 大きく なっ て いく と え いう 流れ が あり ます で これ 理由 は いろいろ ある '
                   'ん です けど も 1 つ 分かり やすい の が やっぱり モデル の サイズ が 大きい ほど 性能 が 上がる '
                   'ん です ね 実 は これ 理論 的 に は まだ 解明 さ れ て い ない ん です けど も 少なく とも '
                   '経験 的 に は 特に あの 自然 言語 を 扱う 自然 言語 モデル の 場合 は モデル の 構造 自体 が '
                   '基本 的 に 変わら なけれ ば ま とにかく その モデル に え 含ま れる パラメーター 数 を 増やせ ば '
                   '増やす ほど 性能 が 良く なる と いう こと が 知ら れ て い て え ニューラル スケーリング ロー と '
                   'いう 名前 が つい て い ます',
  'timestamp': '04:17-04:38'},
 {'Name': '中井 悦司',
  'Transcription': 'で これ を 実証 する 1 つ の 事例 が こちら です ね ま ちょっと もう 今 と なっ て は 古い 話 '
                   'な ん です けど も 2020 年 に GPT3 と 呼ば れる 新しい 自然 言語 モデル が 発表 さ れ て '
                   'これ が ま 非常 に 性能 が いい と いう の で 話題 に なり まし た で Google の 研究 者 '
                   'も これ に 負け て は なら ん と 思っ た か どう か は 分かり ませ ん が ま 翌年 また 新しい '
                   'グラム モデル と いう モデル を 発表 し まし た これ 単純 に あの パラメーター の 数 だけ 比較 '
                   'する と 1 桁 パラメーター が 増え て いる ん です ね で ま その 結果 と し て これ スライド で '
                   '緑 の 数字 が 出 て い ます が ま 5% ない し 10% 程度 確か に 性能 も 向上 し た 上回っ '
                   'た と いう よう な 結果 に なっ て い ます ま 今 現在 あの 生成 AI の 世界 で は とにかく '
                   '大きな モデル を 作っ て より 高い 精度 の 結果 を 出そ うっ て いう 競争 が え 始まっ てる '
                   '広がっ て るっていうのは 皆さん も よく ご存知 の ところ だ と 思い ます',
  'timestamp': '05:13-06:14'},
 {'Name': '中井 悦司',
  'Transcription': 'で ただ これ モデル の サイズ が 大きく なる と あの 単純 に 性能 が 上がる と いう だけ で は '
                   'ない ん です よ ね 他 に も いろいろ メリット が 出 て き ます ま その 1 つ が え 先ほど '
                   'キーワード と し て 登場 し た マルチモーダル です ね 複数 の タイプ の データ を 同時 に 取り扱う '
                   'こと が 得意 に なっ て き ます 今 スライド に 出し て いる の は え 自然 言語 で 何 か こう '
                   '文章 を 入力 する と その 文章 に マッチ し た 画像 を 生成 する ま いわゆる 画像 生成 モデル の '
                   '例 に なり ます で この 画像 生成 モデル も アイデア 自体 は 非常 に 古く から あっ て ずっと '
                   '研究 さ れ て き た ん です けど も やっぱり なかなか いい 結果 が 出 なかっ た ん です ね ま '
                   '最近 に なっ て 非常 に 大 規模 な モデル ま 新しい その モデル の 構造 が 発明 さ れ て え '
                   '非常 に 高い 精度 が 実現 できる よう に なっ た と いう こと に なり ます ま あくまで 一 例 '
                   'です けど も え 2022 年 に Google の 研究 者 が 発表 し た イマージェン と いう モデル '
                   'で は 今 スライド に 映っ て い ます が もう これ ぐらい の え 精度 の 非常 に 綺麗 な 高 精度 '
                   'の 画像 が ジェネレート できる よう に なっ て い ます',
  'timestamp': '06:15-07:22'},
 {'Name': '中井 悦司',
  'Transcription': 'で あと もう 1 つ この マルチモーダル に 関連 し て 今日 是非 ご 紹介 し たい の が こちら の '
                   'モデル な ん です ね これ 何 か ロボット アーム が こう ぶどう を 掴ん で お 皿 に 乗せ て いる '
                   'そんな 動画 が 出 て い ます が え これ ロボット アーム に 対し て こう 命令 を する こと が '
                   'できる ん です ね 例えば テキスト 文 で グレープ を お 皿 に 乗せ なさい と いう と ま その 通り '
                   'この ロボット アーム が 動い て くれる あるいは 動画 で も 構い ませ ん 実際 に 人間 が こう '
                   'ぶどう を 掴ん で お 皿 に 乗せる 様子 を 撮影 し て それ を 入力 する と その 真似 を し て '
                   'ロボット が 動い て くれる と いう もの に なり ます ま 全く 違う 形式 の 入力 データ に 対し て '
                   'ちゃんと 同じ よう に 処理 を し て くれる ま いわゆる マルチモーダル 対応 の 一 例 と いう こと '
                   'に なっ て い ます',
  'timestamp': '07:24-08:13'},
 {'Name': '中井 悦司',
  'Transcription': 'で じゃ 実際 どう やっ て そんな 対応 でき てる ん だ と いう こと な ん です けど も ま 実 は '
                   'これ 仕組み は 意外 と 単純 な ん です ね え 入力 データ の 形式 に 合わせ て 個別 に ま ある '
                   '意味 前 処理 を し て い ます 自然 言語 で 入力 し た 時 は 自然 言語 モデル を 使っ て その '
                   '文章 の 意味 を え 理解 し て その 意味 を 表す ま あの 数学 的 な ベクトル に 変換 する と '
                   'いう こと を やる ん です ね え 潜在 空間 と いう 名前 聞い た こと ある 方 いらっしゃる か も '
                   'しれ ませ ん が ま その 意味 を 表す 抽象 的 な 潜在 空間 の ベクトル に 変換 する で その 後 '
                   'その 意味 ベクトル に 基づい て ロボット アーム を 動かし て いく と いう 形 に なり ます 同様 に '
                   '動画 を 入力 し た 場合 は ま 動画 を 解析 する 専用 の モデル を 使っ て その 動画 の 意味 を '
                   '理解 し て 同じ よう に 潜在 空間 の 意味 ベクトル に 変換 する ま 一旦 その 潜在 空間 の '
                   'ベクトル に 変換 さ れ て しまえ ば その 後 は 全く 同じ よう に 処理 が できる と いう よう な '
                   '仕組み に なり ます ま その 入力 データ に 合わせ て 個別 に 前 処理 を し て で それ を また '
                   'その 潜在 空間 と いう パーツ で こう 1 つ に 統合 する え いろんな 処理 を こう 並列 に 工場 '
                   'の 中 で 流れ 作業 で こう 分担 し て え 処理 し て いく ま そんな 様子 が 想像 できる え '
                   '仕組み じゃ ない か な と 思い ます',
  'timestamp': '08:14-09:34'},
 {'Name': '中井 悦司',
  'Transcription': 'で この 仕組み が 理解 できる と 冒頭 で ご 紹介 し た この ジェフ ディーン の ブログ が え よく '
                   '分かる と 思い ます 実 は この ブログ の 中 で ジェフ ディーン パスウェイズ の 考え 方 は 説明 し '
                   'てる ん です けど も 実際 に それ が どんな 構造 の モデル か まで は あんまり 深く 語っ て い '
                   'ない ん です ね ま な の で これ は あくまで 私 の 想像 に なり ます が おそらく ジェフ ディーン '
                   'こんな こと を 考え てる ん じゃ ない の か な と 思い ます え これ スライド の 図 の 一番 下 '
                   'に タスク と いう 箱 が 並ん で い ます が 実際 に は これ タスク で は なく て あの 入力 '
                   'データ いろんな 形式 の データ を こう 受け付ける 口 が ある ん じゃ ない の か な と 思い ます '
                   'で その データ の 形式 ごと に 個別 の ブロック で 前 処理 を し て 意味 を 取り出し て で '
                   '先ほど の 潜在 空間 を 使っ て 1 つ に まとめ て で さらに マルチタスク いろんな 仕事 を さ せ '
                   'たい ん で あれ ば そっ から また こう ブランチ し て 処理 が 分かれ て いく ま まさに 先ほど '
                   '話し た その 工場 の 中 の 流れ 作業 みたい な そんな 世界 が 1 つ の モデル で 実現 でき て '
                   'ん じゃ ない の か な と 思い ます',
  'timestamp': '09:35-10:01'},
 {'Name': '中井 悦司',
  'Transcription': 'はい ま と いう の が その マルチモーダル マルチタスク の パスウェイズ の 世界 観 な ん です けど '
                   'も じゃ 実際 今 こう いっ た パスウェイズ 的 な モデル が どんどん 登場 し てる か と 言う と 実 '
                   'は まだ これ から な ん です ね 本当 に この パスウェイズ を 実現 する ため に は いくつ か '
                   '乗り越える べき 技術 的 な 課題 が あり ます で その 1 つ が 実 は 単純 に その 超 巨大 な '
                   'パスウェイズ 的 な モデル を 学習 する ため の インフラ な ん です ね まず これ あの 復習 に なり '
                   'ます が え Google 社内 で は Google の 研究 者 は ま 基本 的 に あの Google が '
                   '開発 し た TPU と 呼ば れる プロセッサー で モデル の 学習 処理 を 行っ て い ます 今 スライド '
                   'に 写真 が 映っ て い ます が たくさん の TPU コア を インターコネクト と 呼ば れる 専用 線 で '
                   'こう メッシュ 状 に 結合 し た え クラスター を 使 え 作っ て その クラスター 上 で 分散 学習 '
                   '処理 を 行い ます ま 分散 の さ せ 方 いろいろ ある ん です けど も 基本 的 に は その 巨大 な '
                   '機械 学習 の モデル を こう パーツ に 分解 し て それぞれ の パーツ を 個別 の TPU コア に '
                   'マッピング する で 複数 の TPU コア ば コア が いろんな パーツ を こう 同時 に 並列 に 計算 '
                   'する こと で 高速 に 学習 する ま そんな 感じ の 仕組み に なっ て い ます',
  'timestamp': '10:41-11:11'},
 {'Name': '中井 悦司',
  'Transcription': 'で これ は これ で うまく いっ てる ん です けど も じゃ この まま で その パスウェイズ 的 な 超 '
                   '巨大 な モデル に 対応 できる か と 言う と 実 は だんだん 苦しく なっ て き て いる ん です ね '
                   'ま 単純 に は え この TPU の クラスター これ TPU ポッ トっ て 言う ん です けど も これ の '
                   'サイズ の 限界 です ね やっぱり これ あの インターコネクト で 物理 的 に 配線 し て いる の で '
                   'この クラスター どこ まで も 大きく できる かって 言う と そう で も なく て やっぱり サイズ の '
                   '限界 が あり ます と ま そう する と この 限ら れ た サイズ の クラスター に 超 巨大 な '
                   'パスウェイズ の モデル 全体 が マッピング できる かって 言う と ちょっと 苦しい はみ出し ちゃう ん '
                   'です よ ね さあ どう しよう と いう こと に なり ます',
  'timestamp': '12:00-12:44'},
 {'Name': '中井 悦司',
  'Transcription': 'で この 問題 に 対応 する ため に Google の 研究 者 は ま パスウェイズ 的 な モデル に 対応 '
                   'し た 新しい 分散 学習 の 仕組み を 考え出し て え 論文 発表 し て いる ん です ね で 実際 これ '
                   'Google 社内 で え その インフラ も 実験 的 に 作ら れ て 動い て い ます どんな 仕組み か '
                   'と 言う と ま 割 と あの 発想 単純 な ん です けど も 複数 の クラスター 複数 の TPU ポッ ト '
                   'を 横 に 並べ て ま データ センター ネットワーク で 結合 し て え 同時 に 利用 しよう と いう '
                   'もの に なり ます 1 つ の 巨大 な モデル を こう パーツ に 分解 し て 複数 の TPU ポッ ト '
                   'に マッピング し て え 並列 計算 する と いう こと に なり ます で この 時 異なる TPU ポッ ト '
                   'の 間 で 大量 の データ 転送 が ある と ま そこ は インターコネクト で は なく て 普通 の え '
                   'データ センター ネットワーク な の で 転送 が 遅く て どう し て も ボトルネック に なっ ちゃう ん '
                   'です けど も ま そこ は あの 実 は パスウェイズ 的 な モデル と 非常 に 相性 が いい ん です ね '
                   'え パスウェイズ の モデル と いう の は モデル 全体 と し て は 超 巨大 な ん です けど も 中 '
                   'を 見 て みる と 先ほど 話し た よう に こう ブロック ブロック に 処理 が 分かれ て いる ん です '
                   'ね で それぞれ の ブロック を え 1 つ の TPU ポッ ト に まとめ て マッピング し て あげれ ば '
                   'ま ブロック ごと の 通信 量 は それほど 多く ない の で え 複数 の TPU ポッ ト で も え 特に '
                   'ボトルネック に なら ず に うまく 学習 できる ん じゃ ない か え そんな 考え 方 に なり ます ま '
                   '1 つ の 巨大 な モデル を こう うまく パーツ に 分解 し て え TPU ポッ ト の 複数 の '
                   'クラスター に こう ダイナミック に 動的 に マッピング し て いく そんな スケジューラー の 仕組み も '
                   '彼 ら 考え出し て い ます',
  'timestamp': '12:45-13:44'},
 {'Name': '中井 悦司',
  'Transcription': 'はい で そして 実際 に この インフラ で 初めて 学習 に 成功 し た の が 実 は 先ほど ご 紹介 し '
                   'た え パスウェイズ ランゲージ モデル パーム の 自然 言語 モデル と いう こと に なり ます で 実 は '
                   'あの 先ほど 話し た よう に パーム 自体 は シングル モデル シングル タスク の モデル で あっ て '
                   '本当 の 意味 で の パスウェイズ 的 な モデル で は ない ん です けど も ま ある 意味 これ あの '
                   'パスウェイズ の インフラ の 動作 確認 の ため の POC な ん です ね いきなり その 本格 的 な '
                   'パスウェイズ 的 な モデル を 学習 さ せる と うまく いか なかっ た 時 に どこ が まずい の かって '
                   'いう デバッグ 大変 です よ ね な の で まず は え 普通 の シングル モデル シングル タスク の 自然 '
                   '言語 モデル を あえて この パスウェイズ の インフラ で 学習 さ せ て ま ちゃんと 動く 動く か どう '
                   'か を 確認 し た と いう もの に なり ます え 具体 的 に は 1 つ の 自然 言語 モデル を '
                   'コピー し て 複数 の TPU ポッ ト に マッピング し て ま 同じ モデル を 並列 に 複数 学習 さ '
                   'せる こと で え 非常 に 大量 の データ で 高速 に 学習 さ せる こと に 成功 し た と いう もの '
                   'に なり ます で ただ 結果 的 に これ 非常 に うまく いっ た ん です ね え この パスウェイズ の '
                   'インフラ で 学習 学習 し た 自然 言語 モデル パーム が え これ まで の モデル より も ま さらに '
                   '巨大 な サイズ で さらに 高い 性能 を 発揮 し た と いう こと に なり ます これ あの パスウェイズ '
                   'の インフラ を 開発 し てる チーム から する と ま あくまで インフラ の 動作 確認 に 過ぎ ない ん '
                   'です けど も ま 結果 と し て え 従来 の 自然 言語 モデル を 超える 性能 の いい もの が でき '
                   'た と いう え 状況 に なり ます で 実際 に この え パーム が どんな こと が できる の か ま '
                   'あの 昨年 の Google IO で 紹介 さ れ た 内容 の え 繰り返し に なり ます が 簡単 に ご '
                   '紹介 する と 例えば これ あの 算数 の 問題 を 解く 例 です ね え 自然 言語 モデル と いう の は '
                   '基本 的 に 前半 の 文章 から 後半 の 文章 を 予測 する と いう だけ の もの な ん です けど も '
                   'ま 前半 の 文章 を こう いろいろ 工夫 する と ま それ な に いろんな こと が できる ん です よ '
                   'ね え 算数 の 問題 と 回答 の ペア を 入力 し て また 次 の 問題 を 入力 する ま そう する と '
                   '普通 に 考え て 次 の 問題 の 答え が 絶対 続く はず です よ ね 文章 の 構成 と し て ま な '
                   'の で この パーム は え 2 番目 の 問題 の 答え を ポン と 出し て くれる と いう 形 に なり '
                   'ます で えっと 実 は 単純 に あの 問題 と 答え の ペア だけ だ と 見かけ 上 答え は 出す ん だ '
                   'けど も 計算 が 合わ な いっ て いう こと も もちろん よく あり ます え これ 右側 の 例 で は '
                   'え 1 問 目 の 問題 と 特 手 順 も 含め て 入力 し てる ん です ね ま そう する と 2 問 目 '
                   'の 問題 に 対し て も 特 手 順 含め て 回答 を 出力 し て え ちゃんと 正解 し て くれる ま '
                   '入力 を 工夫 する いわゆる あの プロンプト エンジニアリング え に よっ て いい 答え が 出 て くる '
                   'と いう 例 に なり ます ま 同様 に えっと プログラミング 言語 を 出力 する こと も でき ます と '
                   'ま Python の え 何 か 関数 の 定義 の 冒頭 部分 を 入力 する と ま それ に 続く 後半 の '
                   '実装 を ちゃんと 出力 し て くれる え ま そんな 感じ の 結果 に なり ます',
  'timestamp': '14:29-15:56'},
 {'Name': '中井 悦司',
  'Transcription': 'はい ま じゃ と いう ところ で まとめ に 入り たい と 思い ます え 今日 パスウェイズ と いう ま '
                   'マルチモーダル マルチタスク に 対応 し た 新しい え 機械 学習 モデル の 考え 方 ご 紹介 し まし た '
                   'で それ を 実現 する インフラ は でき てる ん です けど も ま 実際 に その インフラ で 学習 さ '
                   'れ た の は パーム と 呼ば れる 自然 言語 モデル と いう の が 今 の 現状 です 今後 え この '
                   'インフラ を 使っ て ま 本当 の 意味 で の マルチタス マルチモーダル マルチタスク え パスウェイズ 的 '
                   'な モデル が え どんどん 出 て くる ん じゃ ない の か と 期待 し て え 待っ て い たい と '
                   '思い ます さ それ で は 私 から は 以上 に なり ます ご 清聴 ありがとう ござい ます ありがとう '
                   'ござい まし た え それ で は です ね 早速 Q&A に 移り たい と 思い ます 引き続き Q&A の '
                   '進行 務め ます Google Cloud マーケティング の 北瀬 です よろしく お 願い し ます 中井 さん '
                   '引き続き よろしく お 願い し ます はい よろしく お 願い し ます はい じゃ 早速 です けど ね え '
                   '一番 上 の 質問 から 行き たい と 思い ます 中井 さん の 勉強 方法 が 知り たい です どう やっ '
                   'て 情報 収集 や 新しい もの へ の 取り組み を さ れ てる の でしょう か と いう こと です けど '
                   'も 北瀬 さん はい えっと あの 私 個人 に 対する 質問 で 個人 的 に は 非常 に 嬉しい ん です '
                   'けど も これ 多分 語り 出す と 30 分 かかる の で えっと 今日 は すい ませ ん パス さ せ て '
                   'ください あ はい はい あの 是非 次回 の Google Cloud Days で あの 私 の 勉強 法 の '
                   'セッション を 企画 さ せ て いただけれ ば と 思い ます あ いい です ね はい ありがとう ござい ます '
                   'え え 次 です ね え GKE で TPU ポッ ト 利用 できる の でしょう か はい ありがとう ござい '
                   'ます えっと 現状 で は TPU ポッ ト を ダイレクト に GKE に アサイン するっ て いう の は '
                   'なかっ た 気 が し ます ね あの 別途 TPU ポッ ト を えっと Google Cloud 上 で 用意 '
                   'し て ま GKE から えっと タスク を 投げるっ て いう の は もちろん でき ます が ちょっと GKE '
                   'と ダイレクト な インテグレーション は すい ませ ん 私 の 知る 範囲 で は まだ なかっ た と 思い '
                   'ます ありがとう ござい ます 多分 あの この 下 の 質問 も 似 た よう な 感じ に なる ん です か '
                   'ね パスウェイズ の インフラ は Google Cloud の サービス と し て 利用 可能 に なり ます '
                   'か はい その 通り です ね TPU ポッ ト 自体 は 既に あの Google Cloud で 提供 さ れ '
                   'て い ます が その 複数 の TPU ポッ ト を こう ダイナミック に こう 連動 さ せる 仕組み は '
                   'まだ あの サービス と し て は 公開 さ れ て い ない です ね ま ちょっと 将来 的 に どう なる '
                   'か は 私 から は 言え ない ん です けど も ま あの 将来 的 に えっと こう いっ た 技術 が '
                   'クラウド 上 で 利用 に なる 可能 性 は もちろん 十分 ある と 思い ます ありがとう ござい ます '
                   'えっと 最初 の 質問 に 2 で は いる ん です けど も 今 注目 し て いる AI 技術 は 何 '
                   'でしょう か と これ も 個人 的 な 質問 だ と 思い ます けど も いかが でしょう か はい えっと ま '
                   'これ あの 世の中 の 流れ 的 に は 生成 AI って 言っ とく の が 正解 だ と 思う ん です けど '
                   'も あの 私 個人 的 に は 生成 AI その もの より も あの 生成 AI を どう 実用 的 に 使っ て '
                   'いく かって いう えっと アーキテクチャ の 方 に 興味 が あり ます ね あの 生成 AI 単体 で 使っ '
                   'て も あんまり その 実用 的 な ことっ て えっと できる こと 限ら れ て ん です ね おそらく 他 の '
                   '技術 と 生成 AI を こう 組み合わせる 組み合わせ パターン て いう の が 重要 に なる の で ま '
                   'ちょっと そう いう 組み合わせ が 今後 どう いう え 組み合わせ が 出 てる の か 出 て くる の か '
                   'ちょっと 注目 を し て い ます ありがとう ござい ます え じゃ 次 の 質問 行っ て み ましょう か '
                   'え プロンプト チューニング は モデル に 入力 する 内容 を 調整 し て いる だけ で モデル その もの '
                   'を チューニング し て いる わけ で は ない と 思い ます が この 理解 は 正しい です か はい '
                   'えっと 理解 と し て は その 通り だ と 思い ます あの モデル に 入力 する 内容 を こう 本当 に '
                   '工夫 する と いろんな こと が できる の で ま 気持ち と し て こう チューニング と か エンジニア '
                   'リン グっ て いう 気持ち は 分かる ん です けど も これ 機械 学習 の 仕組み を 知っ てる 人間 '
                   'から する と ま ちょっと 気持ち 悪 いっ て いう の は えっと ある と 思い ます モデル その もの '
                   'を こう いじっ てる わけ で は なく て あくまで モデル に 入力 する 内容 を え いろいろ '
                   'チューニング し てる と いう の が プロンプト チューニング の 位置づけ に なり ます ありがとう ござい '
                   'ます じゃ 次 で 最後 の 質問 に 行き ましょう か え 今後 モデル の サイズ を 圧縮 する 技術 が '
                   '発達 し て も やはり 大 規模 な モデル は 必要 な の でしょう か と いう ところ です か はい '
                   'ありがとう ござい ます これ いい 質問 だ と 思い ます が 基本 的 に 私 は 必要 だ と 思っ て い '
                   'ます と いう の は あの モデル を 圧縮 する 技術 と いう の は あくまで 圧縮 する 元 に なる え '
                   '大 規模 な モ デ ルっ て いう の は やっぱり 誰 か が 作る 必要 が ある ん です よ ね ま それ '
                   'を その 1 ユーザー が 自分 で 作 るっ て いう 場面 は あんまり ない か と 思い ます が えっと '
                   'やはり その 大 規模 な 分散 インフラ を 持っ て いる え 企業 が まず は その 大 規模 な 新しい '
                   'モデル を どんどん どんどん 作っ て いっ て で それ を また え 圧縮 する 技術 を 組み合わせ て '
                   '個人 で も 利用 が できる よう な 簡単 に 利用 できる 環境 が え 整っ て いく ま そんな 流れ は '
                   '今後 も 続く ん じゃ ない の か な と 思っ て い ます ありがとう ござい ます じゃ こちら で です '
                   'ね えっと セッション の 方 は 終了 し たい し たい と 思い ます え ありがとう ござい まし た はい '
                   'ありがとう ござい ます',
  'timestamp': '17:43-18:22'}]

[texts]
[{'Layout': '中央に文字列',
  'Text': ['DAY', 'Breakout', 'Breakout Session'],
  'Timestamp': '00:01-00:05'},
 {'Layout': '左上に「Google Cloud」ロゴ、右上に「DAY '
            'Tour」ロゴ、中央にタイトル、中央下に名前、左下に所属、右下にハッシュタグ',
  'Text': ['Google Cloud',
           'DAY',
           'Tour',
           '大規模言語モデルを支える',
           '分散学習インフラ Pathways',
           '中井 悦司 / Etsuji Nakai',
           'Google Cloud / ソリューションズ アーキテクト',
           '#GoogleCloudDay'],
  'Timestamp': '00:05-00:12'},
 {'Layout': '左下に名前、左下に所属、右下にハッシュタグ',
  'Text': ['中井 悦司', 'Google Cloud', 'ソリューションズ アーキテクト', '#GoogleCloudDay'],
  'Timestamp': '00:23-00:29'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央に「自己紹介」、中央下に名前、左下に所属、右下にハッシュタグ、中央に人物写真、その下に書籍画像',
  'Text': ['DAY',
           'Tour',
           '自己紹介',
           '中井 悦司 / Etsuji Nakai',
           'Google Cloud / ソリューションズ アーキテクト',
           'Google Cloud',
           '#GoogleCloudDay'],
  'Timestamp': '00:29-00:34'},
 {'Layout': '左上に「DAY '
            'Tour」ロゴ、中央にタイトル、左下に投稿者名、左下に投稿日時、右下にハッシュタグ、中央に図、その下に説明文、右に人物写真',
  'Text': ['DAY',
           'Tour',
           'Introducing Pathways: A next-generation',
           'AI architecture',
           'Oct 28, 2021',
           '5 min read',
           'Jeff Dean',
           'Google Senior Fellow and SVP',
           'Google Research',
           'Introducing Pathways: A next-generation AI architecture | The '
           'Keyword | Google',
           'https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/',
           'Google Cloud',
           '#GoogleCloudDay',
           'Task 1',
           'Task 2',
           'Task 3',
           'Task I',
           'Output',
           'Output',
           'Output',
           '8 billion parameters',
           '12 billion parameters',
           '48 billion parameters',
           '62 billion parameters',
           '138 billion parameters',
           '472 billion parameters',
           '540 billion parameters',
           'Pathways Language Model (PaLM): Scaling to 540 Billion Parameters '
           'for Breakthrough Performance',
           'BLOG',
           'MONDAY, APRIL 04, 2022',
           'Posted by Sharan Narang and Aakanksha Chowdhery, Software '
           'Engineers, Google Research',
           'Pathways Language Model (PaLM): Scaling to 540 Billion Parameters '
           'for Breakthrough Performance | Blog | Google Research',
           'https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html',
           'LANGUAGE UNDERSTANDING',
           'ARITHMETIC',
           'SUMMARIZATION',
           'TRANSLATION',
           'QUESTION ANSWERING',
           'CODE COMPLETION',
           'LOGICAL INFERENCE CHAINS',
           'COMMON-SENSE REASONING',
           'PATTERN RECOGNITION',
           'JOKE EXPLANATIONS',
           'PHYSICS QA',
           'DIALOGUE',
           'PROVERBS',
           'SEMANTIC PARSING',
           'GENERAL KNOWLEDGE',
           'READING COMPREHENSION'],
  'Timestamp': '00:34-01:53'},
 {'Layout': '左上に「DAY '
            'Tour」ロゴ、右上に「BLOG」ロゴ、中央にタイトル、左下に投稿者名、左下に投稿日時、右下にハッシュタグ、中央に図、その下に説明文、右に人物写真、右下に説明文',
  'Text': ['DAY',
           'Tour',
           'BLOG',
           'Pathways Language Model (PaLM): Scaling to 540 Billion',
           'Parameters for Breakthrough Performance',
           'MONDAY, APRIL 04, 2022',
           'Posted by Sharan Narang and Aakanksha Chowdhery, Software '
           'Engineers, Google Research',
           '8 billion parameters',
           'Pathways Language Model PaLM: Scaling to 540 Billion Parameters '
           'for Breakthrough Performance | Blog | Google Research',
           'https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html',
           'Google Cloud',
           '12 billion parameters',
           '48 billion parameters',
           'LANGUAGE UNDERSTANDING',
           'ARITHMETIC',
           '62 billion parameters',
           'TRANSLATION',
           'QUESTION ANSWERING',
           'SUMMARIZATION',
           '138 billion parameters',
           'LOGICAL INFERENCE CHAINS',
           'COMMON-SENSE REASONING',
           'PATTERN RECOGNITION',
           'QUESTION ANSWERING',
           'SEMANTIC PARSING',
           'PROVERBS',
           'ARITHMETIC',
           'CODE COMPLETION',
           'GENERAL KNOWLEDGE',
           'READING COMPREHENSION',
           'SUMMARIZATION',
           'LANGUAGE UNDERSTANDING',
           'TRANSLATION',
           'DIALOGUE',
           'JOKE EXPLANATIONS',
           'PHYSICS QA',
           '427 billion parameters',
           '540 billion parameters',
           '#GoogleCloudDay'],
  'Timestamp': '01:53-03:14'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央にタイトル、右下にハッシュタグ、右に人物写真',
  'Text': ['DAY', 'Tour', 'Pathwaysのアイデアが', '生まれた背景', '#GoogleCloudDay'],
  'Timestamp': '03:14-03:21'},
 {'Layout': '左上に「DAY '
            'Tour」ロゴ、中央にタイトル、左下に投稿者名、左下に投稿日時、右下にハッシュタグ、中央に図、その下に説明文、右に人物写真',
  'Text': ['DAY',
           'Tour',
           'ディープラーニング実用化のきっかけ',
           '(2012年の発表)',
           'Using large-scale brain simulations for',
           'machine learning and A.I.',
           'Jun 26, 2012',
           '3 min read',
           'Jeff Dean',
           'Google Senior Fellow and SVP',
           'and SVP, Google AI',
           'Andrew Ng',
           'Visiting Faculty',
           'Using large-scale brain simulations for machine learning and A.I. '
           '| The Keyword | Google',
           'https://blog.google/technology/ai/using-large-scale-brain-simulations-for/',
           'Google Cloud',
           '#GoogleCloudDay'],
  'Timestamp': '03:21-04:17'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央にタイトル、右上に「Used across '
            'products:」、右下にハッシュタグ、中央左にグラフ、その下に説明文、中央右にGoogle製品ロゴ、右に人物写真',
  'Text': ['DAY',
           'Tour',
           'Googleでのディープラーニングの利用実績',
           'Google 3 directories containing Brain Model',
           'Unique project directories',
           'Time',
           'Used across products:',
           'https://www.slideshare.net/timbodennis/google-deep-learning-for-building-intelligent-computer-systems-a-keynote-presentation-from-google',
           'Google Cloud',
           '#GoogleCloudDay'],
  'Timestamp': '04:17-04:28'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央にグラフ、その下に説明文、右に人物写真',
  'Text': ['DAY',
           'Tour',
           'Neural scaling laws',
           '● 自然言語モデル／画像モデルでは、モデルの規模が大きくなる方向に進んでおり、「計算',
           '量（モデルサイズ、データ量）」が指数関数的により大きな影響を与えるという経',
           '験則 (2020 / 2021年)',
           'Test Loss',
           'Compute',
           'non-embedding',
           'PF-language model embedding',
           'Dataset Size',
           'non-embedding',
           'PF-language model embedding',
           'Parameters',
           'non-embedding',
           'PF-language model embedding',
           'Figure 1. Language modeling performance improves smoothly as we '
           'increase the model size, dataset',
           'size, and amount of compute used for training. For optimal '
           'performance all three factors must be scaled',
           'up in tandem. Empirical performance has a power-law relationship '
           'with each individual factor when not',
           'bottlenecked by the other two.',
           'Scaling Laws for Neural Language Models | arXiv | Cornell '
           'University',
           'https://arxiv.org/abs/2001.08361',
           'Google Cloud',
           '#GoogleCloudDay'],
  'Timestamp': '04:28-05:13'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央左に説明文、その下に表、右下に説明文、右に人物写真',
  'Text': ['Neural scaling laws',
           '• GPT-3 モデル（2020 年）：1,750 億パラメーター',
           '↓',
           '• GLaM モデル（2021 年）：1 兆 2,000 億パラメーター',
           '○ '
           'https://ai.googleblog.com/2021/12/more-efficient-in-context-learning-with.html',
           'GPT-3 に対する',
           'GLaM の性能向上'],
  'Timestamp': '05:13-06:15'},
 {'Layout': '左上に「DAY '
            'Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央左に説明文、その下に説明文、右下に説明文、中央右に図、その下に説明文、右に人物写真',
  'Text': ['「マルチモーダル」なデータを使うモデル',
           '• 入力と出力でデータの種類が',
           '異なるパターン',
           '例：「テキスト」→「画像」',
           '• XMC-GAN（2021 年）',
           '学習方法を工夫して、',
           'より高い忠実度を達成',
           'テキストから画像を',
           '生成するモデル'],
  'Timestamp': '06:15-07:07'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央に図、その下に説明文、右に人物写真',
  'Text': ['「マルチモーダル」なデータを使うモデル', '• Imagen（2022）'],
  'Timestamp': '07:07-07:23'},
 {'Layout': '左上に「DAY '
            'Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央に図、その下に説明文、右に人物写真、左に説明文、右上に説明文',
  'Text': ['複数 の「命令方法」によるロボット操作',
           '• BC-Z: Zero-Shot Task Generalization with Robotic Imitation '
           'Learning（2021 年）',
           '○ 自然言語、もしくは、実演映像による指示でロボットを操作するモデル',
           'Place grapes in',
           'ceramic bowl',
           '自然言語による指示',
           '実演映像による指示',
           '模倣ではない',
           'ロボットの動作'],
  'Timestamp': '07:23-08:14'},
 {'Layout': '左上に「DAY '
            'Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央に図、その下に説明文、右に人物写真、左下に説明文、中央下に説明文',
  'Text': ['異なる表現形式を統一的に取り扱う仕組み',
           '• 複数の「意味」を表した共通の潜在空間（特徴量空間）を介することで、複数',
           'の表現形式を統合',
           '自然言語と実演映像を',
           '同一の潜在空間に',
           'マッピング',
           '“Place the bottle for the ceramic bowl”',
           'パーツを結合するための新たなパーツ'],
  'Timestamp': '08:14-09:35'},
 {'Layout': '左上に「DAY '
            'Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央に図、その下に説明文、右に人物写真、左に説明文、右上に説明文、左下に説明文',
  'Text': ['Pathways のモデル構造（予想）',
           'Output',
           'Output',
           'Output',
           'Output',
           '役割ごとの「パーツ」となる',
           'ブロック（サブグラフ）を担う複数',
           'タスクに応じて重み再',
           '役割ごとのタスクの訓練を',
           '独立に並列化',
           'することで、マルチモーダルな',
           'データに対して複数のタスクを並',
           '列に実行',
           '複数のデータの情報を',
           '混ぜ込む処理を',
           '共通の処理で表現',
           'タスクに応じて重み分岐',
           'データの種類に応じた',
           '（共通）モデル',
           'パーツを共有することで、全体の',
           '学習がより効率的に進むと考えら',
           'れる',
           'マルチモーダルな',
           'データを入力',
           'Task 1',
           'Task 2',
           '...',
           'Task N'],
  'Timestamp': '09:35-10:41'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央にタイトル、右下にハッシュタグ、右に人物写真',
  'Text': ['Pathways の実現に向けた', '技術開発'],
  'Timestamp': '10:41-11:04'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央左に図、その下に説明文、中央右に図、右に人物写真',
  'Text': ['TPU Pod',
           'TPU Core を搭載したボードを使用の専用インターコネクトで相互接続',
           'Google showcases Cloud TPU v4 Pods for large-model training | Blog '
           '| Google Cloud',
           'https://cloud.google.com/blog/products/ai-machine-learning/google-showcases-cloud-tpu-v4-pods-for-large-model-training'],
  'Timestamp': '11:04-11:38'},
 {'Layout': '左上に「DAY '
            'Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央左に説明文、その下に説明文、中央右に図、その上に説明文、右に人物写真',
  'Text': ['TPU Pod による計算処理',
           'モデルの必要なコンポーネントを TPU Core にマップ',
           'して、同期的に計算を実行',
           'インターコネクトを介して、TPU Core 間は、仕',
           '事量を相互に交換',
           'データフローコンポーネントネットワーク',
           '入力',
           'TPU コア',
           'ML モデル',
           'インターコネクトによる高速なメッセージ通信が',
           'パフォーマンスを実現するポイント',
           'Host',
           'Host',
           'Ctrl',
           'Ctrl',
           'Dev',
           'Dev',
           'Dev',
           'Dev',
           'Ctrl',
           'Ctrl',
           'Host',
           'Host',
           'step 0',
           'step 1',
           'step 2',
           'step 3',
           'Pathways: Asynchronous Distributed Dataflow for ML (arXiv) | '
           'Cornell University',
           'https://arxiv.org/abs/2203.12533'],
  'Timestamp': '11:38-12:45'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央に説明文、右に人物写真',
  'Text': ['Pathways に対応した計算モデルの提案（2022年）',
           'PATHWAYS: ASYNCHRONOUS DISTRIBUTED DATAFLOW FOR ML',
           'ABSTRACT',
           'We present the design of a new large-scale orchestration layer for '
           'accelerators. Our system, Pathways, is',
           'explicitly designed to enable efficient execution of heterogeneous '
           'ML workloads, while maintaining state-of-the-',
           'art performance and model quality. Pathways uses sharded and '
           'heterogeneous parallel computations operating on',
           'commodity processor cores, mobile system-on-chips, and ML '
           'accelerators. A key design principle of Pathways is that',
           'accelerators are disaggregated, enabling their use in a shared '
           'pool. Pathways also disaggregates model state in the',
           'accelerators, allowing different dataflow engines to be '
           'interleaved to execute a single model deployed on thousands of',
           'accelerators. This disaggregated design, along with the '
           'decentralized execution adopted in Pathways, makes it robust in '
           'the',
           'presence of wide-area distributed training over slow, lossy '
           'interconnects. Pathways simplifies model construction at a novel',
           'dataflow level, where centralized control flow over the entire '
           "distributed system is largely decoupled from the model's",
           'dataflow. This simplifies partitioning and allows the dataflow to '
           'be easily adapted to individual models. We make a',
           'case for the expressiveness of this new dataflow paradigm by '
           'demonstrating that Pathways can achieve performance',
           'parity (97% - 101%) compared with state-of-the-art TPU systems for '
           'training. Training speed comparisons are',
           'provided for both image classification and language modeling. We '
           'also show that Pathways can maintain this',
           'performance even when using new compute patterns. We demonstrate '
           'that Pathways can achieve performance that',
           'is 200% - 400% faster than existing state-of-the-art systems for '
           'sparse model training. Finally, we demonstrate that',
           'Pathways achieves near-linear scaling with up to 4,096 TPU v4 '
           'chips spread across two data center networks.',
           'Pathways: Asynchronous Distributed Dataflow for ML (arXiv) | '
           'Cornell University',
           'https://arxiv.org/abs/2203.12533'],
  'Timestamp': '12:45-13:03'},
 {'Layout': '左上に「DAY '
            'Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央左に説明文、その下に説明文、中央右に図、その上に説明文、右に人物写真',
  'Text': ['Pathways に対応した計算モデルの提案（2022年）',
           'Pathways を構成するノードごとに TPU Pod 内のスライス（小規模）にマッピング',
           'ノード内の分散は、インターコネクトを介して高速に実行',
           'ノード間のデータ転送は、高速なデータセンターネットワークを介して行う'],
  'Timestamp': '13:03-14:28'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央に説明文、右に人物写真',
  'Text': ['TPU Pod の課題と解決策'],
  'Timestamp': '14:28-14:29'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央に説明文、右に人物写真',
  'Text': ['Pathways のインフラを用いた学習処理の実施例（2022年）'],
  'Timestamp': '14:29-14:41'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央左に説明文、その下に説明文、中央右に図、右に人物写真',
  'Text': ['Pathways のインフラを用いた学習処理の実施例（2022年）',
           '学習対象のモデルは、Transformer を用いた自然言語モデル',
           '○ 入力文章に対して、次の単語（の確率）を予測するシンプルなモデル',
           '○ 予測した単語を再帰的に入力することで、 複数の文章生成が可能',
           '同一モデルの学習に 2 つの TPU Pod にマッピングして、データ並列で学習',
           '○ 6144 個の TPU v4 チップを使用',
           'スパースデータを用いて、勾配計算と更新処理（パラメータ更新）を交互に実行'],
  'Timestamp': '14:41-15:40'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央左に説明文、その下に表、右下に説明文、右に人物写真',
  'Text': ['PaLM の性能',
           '従来より大きなサイズのモデルの学習に成功',
           'これまで大きな自然言語タスクに対して、 従来の最高精度を更新',
           'これまでのモデルの性能の限界'],
  'Timestamp': '15:40-16:12'},
 {'Layout': '左上に「DAY '
            'Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央左に図、その下に説明文、中央右に図、その下に説明文、右に人物写真',
  'Text': ['PaLM による 1-shot learning の実行例',
           'Standard prompting',
           'Chain of thought prompting',
           'Input:',
           'Q: Roger has 5 tennis balls. He buys 2 more cans',
           'of tennis balls. Each can has 3 tennis balls. How',
           'many tennis balls does he have now?',
           'A: The answer is 11.',
           'Input:',
           'Q: Roger has 5 tennis balls. He buys 2 more cans',
           'of tennis balls. Each can has 3 tennis balls. How',
           'many tennis balls does he have now?',
           'A: Roger started with 5 balls. 2 cans of 3 tennis',
           'balls each is 6 balls so 5 + 6 = 11. The answer',
           'is 11.',
           'Q: The cafeteria had 23 apples. If they used 20 to',
           'make lunch and bought 6 more, how many apples',
           'do they have?',
           'A:',
           'Model',
           'output:',
           'The answer is 50. ×',
           'Q: The cafeteria had 23 apples. If they used 20 to',
           'make lunch and bought 6 more, how many apples',
           'do they have?',
           'A: The cafeteria had 23 apples originally. They used',
           '20 to make lunch so they had 23 - 20 = 3. They',
           'bought 6 more apples, so they have 3 + 6 = 9. The',
           'answer is 9.',
           'Model',
           'output:',
           'シンプルに質問だけをして',
           '正解を求める',
           '推論過程を言語でつな',
           'げる事を求める事で正解',
           'Google Cloud'],
  'Timestamp': '16:12-17:26'},
 {'Layout': '左上に「DAY '
            'Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央左に図、その上に「prompt」ロゴ、左下に「model」ロゴ、右上に図、その上に「prompt」ロゴ、右下に「model」ロゴ、右に人物写真、中央左に説明文、中央右に説明文',
  'Text': ['PaLM によるプログラムコードの出力例',
           'prompt',
           'def exercise5():',
           '""',
           'Marie ordered one chicken meal that costs $12.5',
           'packs of milk that costs $3 each, 4 apples that cost',
           '$1.50 each, and some boxes of pizza. Marie paid a total',
           'of $90. How many boxes of pizza did Marie order if each',
           'box costs $9.50?""',
           'total_paid = 90',
           'cost_of_pizza_per_box = 9.50',
           'cost_of_chicken_meal = 12.5',
           'cost_of_milk_per_pack = 3',
           'cost_of_apple_per_apple = 1.50',
           'return round((total_paid - cost_of_chicken_meal -',
           'cost_of_milk_per_pack *',
           'packages_of_milk - cost_of_apple_per_apple *',
           'number_of_apples) / cost_of_pizza_per_box)',
           '41 cost_of_pizza_per_box',
           'prompt',
           'model',
           'Given a string representing musical notes in a',
           'special ASCII format,',
           'parse the string and compute a total length of the',
           'musical piece.',
           '""',
           'legend:',
           "'o' - whole note",
           "'o|' - dotted whole note",
           "'.' - quarter note",
           "'|' - eighth note",
           '""',
           'For example:',
           "'o o| . | o| . | o . . |'",
           'model',
           'def notes(s):',
           'length = 0',
           'notes = notes(s)',
           'total_length = 0',
           "if notes == 'o':",
           'total_length += 4',
           "if notes == 'o|':",
           'total_length += 6',
           "if notes == '.':",
           'total_length += 1',
           "if notes == '|':",
           'total_length += 0.5',
           'return total_length',
           '問題文の後の',
           'コメント部分を入力',
           'コメントに準拠の',
           '本体を出力',
           'Google Cloud'],
  'Timestamp': '17:26-17:42'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央にタイトル、右下にハッシュタグ、中央に説明文、右に人物写真',
  'Text': ['まとめ',
           '• モデルサイズの拡大に伴う性能向上は今後も継続すると期待される一方、巨大',
           'なモデルを学習するためのインフラには限界がある',
           '• 複数の TPU Pod を接続統合させた新しい学習システムを構想・実装',
           '○ 従来のサイズを超える革新的な自然言語モデル (PaLM) の学習に成功',
           '• 将来は、Pathways が実現する規模拡張タスク・マルチモーダルに対応したモデル',
           'の学習に利用できる期待される',
           'Google Cloud',
           '#GoogleCloudDay'],
  'Timestamp': '17:42-18:18'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央に「Thank you.」、右下にハッシュタグ、右に人物写真',
  'Text': ['DAY', 'Tour', 'Thank you.', '#GoogleCloudDay'],
  'Timestamp': '18:18-18:25'},
 {'Layout': '左下に名前、左下に所属、右下にハッシュタグ',
  'Text': ['北瀬 公彦', 'Google Cloud', 'マーケティング', '#GoogleCloudDay'],
  'Timestamp': '18:33-18:37'},
 {'Layout': '左上に「DAY '
            'Tour」ロゴ、右上に「こちらで参加」ロゴ、中央に「slido.com」、中央に「#gcd_qa」、右下にハッシュタグ',
  'Text': ['こちらで参加', 'slido.com', '#gcd_qa', '#GoogleCloudDay'],
  'Timestamp': '18:37-18:40'},
 {'Layout': '左上に「DAY Tour」ロゴ、右上に「slido」ロゴ、中央に質問、右下にハッシュタグ、左に人物写真、右に人物写真',
  'Text': ['中井さんの解説が迫力満点でしたが、どうやって情報収集や新しい',
           'ものへの取り組みをされているのでしょうか？',
           'GKEでTPU Podを利用できるのでしょうか。',
           '今注目しているAI技術はなんでしょうか？',
           '#GoogleCloudDay'],
  'Timestamp': '18:40-19:51'},
 {'Layout': '左上に「DAY '
            'Tour」ロゴ、右上に「slido」ロゴ、中央に質問、右下にハッシュタグ、左に人物写真、右に人物写真、左上に回答、右上に回答',
  'Text': ['GKEでTPU Podを利用できるのでしょうか。',
           '0台',
           '中井さんの解説が迫力満点でしたが、どうやって情報収集や新しい',
           'ものへの取り組みをされているのでしょうか？',
           '0台',
           '今注目しているAI技術はなんでしょうか？',
           '0台',
           'プロンプトチューニングは、モデルに入力する内容を調整している',
           'だけで、モデルそのものをチューニングしているわけではないと聞き',
           'ったので、その認識は正しいでしょうか？',
           '0台',
           '今後、モデルのサイズを圧倒する技術が登場しても、やはり大規模',
           'なモデルは必要なのでしょうか？',
           '#GoogleCloudDay'],
  'Timestamp': '19:51-23:04'},
 {'Layout': '左上に「DAY Tour」ロゴ、中央に「Thank you.」、右下にハッシュタグ',
  'Text': ['Thank you.', '#GoogleCloudDay'],
  'Timestamp': '23:04-23:06'},
 {'Layout': '中央に「Google Cloud」ロゴ',
  'Text': ['Google Cloud'],
  'Timestamp': '23:06-23:15'}]